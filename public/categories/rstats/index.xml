<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rstats on Data Se</title>
    <link>/categories/rstats/</link>
    <description>Recent content in Rstats on Data Se</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/rstats/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Changing the default color scheme in ggplot2</title>
      <link>/2018/12/12/changing-the-default-color-scheme-in-ggplot2/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/12/changing-the-default-color-scheme-in-ggplot2/</guid>
      <description>The default color scheme in ggplot2 is suitable for many purposes, but, for instance, it is not suitable for b/w printing, and maybe not suitable for persons with limited color perception.
Of course, it is straightforward to edit the color scheme for one given plot. But how to change the default color scheme in ggplot2?
As it turns out, there are some helpful ways to address that – Kudos to @ben-bolker who helped me out on this Stackoverflow post.</description>
    </item>
    
    <item>
      <title>New split-apply-combine variant in dplyr: group_split()</title>
      <link>/2018/12/10/new-split-apply-combine-variant-in-dplyr-group-split/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/10/new-split-apply-combine-variant-in-dplyr-group-split/</guid>
      <description>UPDATE 2018-12-11 - I’m talking about the package DPLYR, not PURRR, as I had mistakenly written.
There are many approaches for what is called the “split-apply-combine” approach (see this paper by Hadley Wickham).
I recently thought about the best approach to use split-apply-combine approaches in R (see tweet, and this post).
And I retweeted some criticism on the “present era” tidyverse approach (see this tweet), and check out the mentioned post by @coolbutuseless.</description>
    </item>
    
    <item>
      <title>Applying a function to each row of a data frame</title>
      <link>/2018/12/07/applying-a-function-to-each-row-of-a-data-frame/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/07/applying-a-function-to-each-row-of-a-data-frame/</guid>
      <description>A typical and quite straight forward operation in R and the tidyverse is to apply a function on each column of a data frame (or on each element of a list, which is the same for that regard).
However, the orthogonal question of “how to apply a function on each row” is much less labored. We will look at this question in this post, and explore some (of many) answers to this question.</description>
    </item>
    
    <item>
      <title>Coercing an index over a character vector</title>
      <link>/2018/12/06/coercing-an-index-over-a-character-vector/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/06/coercing-an-index-over-a-character-vector/</guid>
      <description>Assume we have a vector (of type character) such as countries, names, or products. Each element is allowed to show up multiple times. Further assume that there is a rather large number of unique (different) elements. What we would like to achieve is to give each element a unique ID, where the ID ranges from 1 to k (k is the number of different elements).
Of course there are different ways to achieve this goal, we’ll explore one or two.</description>
    </item>
    
    <item>
      <title>Plot many ggplot diagrams using nest() and map()</title>
      <link>/2018/12/05/plot-many-ggplot-diagrams-using-nest-and-map/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/05/plot-many-ggplot-diagrams-using-nest-and-map/</guid>
      <description>At times, it is helpful to plot a multiple of related diagrams, such as a scatter plot for each subgroup. As always, there a number of ways of doing so in R. Specifically, we will make use of ggplot2.
library(tidyverse) library(glue) data(mtcars) d &amp;lt;- mtcars %&amp;gt;% rownames_to_column(var = &amp;quot;car_names&amp;quot;) Is d a tibble`
is_tibble(d) #&amp;gt; [1] FALSE What is it?
class(d) #&amp;gt; [1] &amp;quot;data.frame&amp;quot; Okay, let’s make a tibble out of it:</description>
    </item>
    
    <item>
      <title>What are the names of the cars with 4 cylinders?</title>
      <link>/2018/12/03/what-are-the-names-of-the-cars-with-4-cylinders/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/03/what-are-the-names-of-the-cars-with-4-cylinders/</guid>
      <description>Recently, some one asked me in a workshop this question: “What are the names of the cars with 4 (6,8) cylinders?” (he referred to the mtcars data set). That was a workshop on the tidyverse, so the question is how to answer this question using tidyverse techniques.
First, let’s load the usual culprits.
library(tidyverse) library(purrrlyr) library(knitr) library(stringr) data(mtcars) d &amp;lt;- as_tibble(mtcars) %&amp;gt;% rownames_to_column(var = &amp;quot;car_names&amp;quot;) d %&amp;gt;% head() %&amp;gt;% kable()   car_names mpg cyl disp hp drat wt qsec vs am gear carb    Mazda RX4 21.</description>
    </item>
    
    <item>
      <title>Image paths in Hugo/blogdown</title>
      <link>/2018/11/28/image-paths-in-hugo-blogdown/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/28/image-paths-in-hugo-blogdown/</guid>
      <description>Images from R are instantly included into (R) markdown files, and the same applies for blogdown posts.
See:
x &amp;lt;- 1:10 plot(x) However, for external images - such as photos - things are more complicated. First, all is still fine, if an image is found on some URL/server on the internet:
knitr::include_graphics(&amp;quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/R_logo.svg/310px-R_logo.svg.png&amp;quot;) Of course, one can apply direct markdown syntax for including external images:
![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/R_logo.svg/310px-R_logo.svg.png){width=20%} Now assume we are in an R project that gives the base for a blogdown blog.</description>
    </item>
    
    <item>
      <title>Compute all pairwise differences in matrix</title>
      <link>/2018/11/21/compute-all-pairwise-differences-in-matrix/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/21/compute-all-pairwise-differences-in-matrix/</guid>
      <description>A quite frequent task in many fields of applied math is to compute pairwise differences of elements in a matrix. Actually, it need not be a difference; a product is frequent, too. In this post, we explore some (base) R ways to achieve this.
library(mosaic) library(gdata) library(tidyverse) Using outer() An elegant approach, using base R, is applying outer(). That’s useful if one has two vectors, and wants to compute the outer product:</description>
    </item>
    
    <item>
      <title>Slides for the „hands-on data exploration workshop&#34;</title>
      <link>/2018/11/12/slides-for-the-hands-on-data-exploration-workshop/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/12/slides-for-the-hands-on-data-exploration-workshop/</guid>
      <description>Find the slides for my workshop “hands-on data exploration using R” here: http://data-se.netlify.com/slides/hands-on-data-exploration/handson-data-workshop_2018-11-21.html.
Note that the slides need access to the internet, in order to be rendered correctly.
: Get PDF of slides here
: Get Rmd source code of slides here
The workshop is delivered at the Data Natives Conference 2018 Berlin.</description>
    </item>
    
    <item>
      <title>Simple Examples with DiagrammeR</title>
      <link>/2018/11/07/simple-examples-with-diagrammer/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/07/simple-examples-with-diagrammer/</guid>
      <description>Here are some examples of diagrams build with DiagrammeR:
library(tidyverse) library(DiagrammeR) grViz(&amp;quot; digraph boxes_and_circles { graph [layout = circo, overlap = true] node [shape = circle, fixedsize = true, fontname = Helvetica, width = 1] Problem; Plan; Data; Analysis; Conclusion edge [color = grey] Problem -&amp;gt; Plan Plan -&amp;gt; Data Data -&amp;gt; Analysis Analysis -&amp;gt; Conclusion Conclusion -&amp;gt; Problem } &amp;quot;)  {&#34;x&#34;:{&#34;diagram&#34;:&#34;\ndigraph boxes_and_circles {\n graph [layout = circo,\n overlap = true]\n\n node [shape = circle,\n fixedsize = true,\n fontname = Helvetica,\n width = 1]\n Problem; Plan; Data; Analysis; Conclusion\n \n\n edge [color = grey] \n Problem - Plan\n Plan - Data\n Data - Analysis\n Analysis - Conclusion\n Conclusion - Problem\n }\n &#34;</description>
    </item>
    
    <item>
      <title>Plot columns repeatedly</title>
      <link>/2018/11/02/plot-columns-repeatedly/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/02/plot-columns-repeatedly/</guid>
      <description>Suppose you have a large number of columns of a dataframe, and you want to plot each column – say a histogram for each column.
This post shows some ways of achieving this.
Let’s take the mtcars dataset as an example.
data(mtcars) We will use the tidyverse approach:
library(tidyverse) Way 1 mtcars %&amp;gt;% select_if(is_numeric) %&amp;gt;% map2(., names(.), ~ {ggplot(data = data_frame(.x), aes(x = .x)) + geom_histogram() + labs(x= .y)}) #&amp;gt; $mpg #&amp;gt; #&amp;gt; $cyl #&amp;gt; #&amp;gt; $disp #&amp;gt; #&amp;gt; $hp #&amp;gt; #&amp;gt; $drat #&amp;gt; #&amp;gt; $wt #&amp;gt; #&amp;gt; $qsec #&amp;gt; #&amp;gt; $vs #&amp;gt; #&amp;gt; $am #&amp;gt; #&amp;gt; $gear #&amp;gt; #&amp;gt; $carb Some explanations:</description>
    </item>
    
    <item>
      <title>OECD Wellbegin - Explorative Analysis</title>
      <link>/2018/10/16/oecd-wellbegin-explorative-analysis/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/16/oecd-wellbegin-explorative-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>OECD Wellbeing - Explorative Analyse</title>
      <link>/2018/10/16/oecd-wellbeing-explorative-analyse/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/16/oecd-wellbeing-explorative-analyse/</guid>
      <description>In diesem Post untersuchen wir einige Aspekte der explorativen Datenanalyse für den Datensatz oecd wellbeing aus dem Jahr 2016.
Hinweis: Als Vertiefung gekennzeichnete Abschnitt sind nicht prüfungsrelevant.
Benötigte Pakete Ein Standard-Paket zur grundlegenden Datenanalyse:
library(mosaic)  Datensatz laden Der Datensatz kann hier bezogen werden.
Doi: https://doi.org/10.1787/data-00707-en.
Falls der Datensatz lokal (auf Ihrem Rechner) vorliegt, können Sie ihn in gewohnter Manier laden. Geben Sie dazu den Pfad zum Datensatz ein:</description>
    </item>
    
    <item>
      <title>OECD Wellbeing dataset (2016)</title>
      <link>/2018/10/16/oecd-wellbeing-dataset-2016/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/16/oecd-wellbeing-dataset-2016/</guid>
      <description>Packages We will need the following packages in this post:
library(mosaic) library(knitr) library(DT)  The OECD wellbeing study series The OECD keeps measuring the wellbeing (and associated variables) among its members states.
On the project website, the OECD states:
 In recent years, concerns have emerged regarding the fact that macro-economic statistics, such as GDP, don’t provide a sufficiently detailed picture of the living conditions that ordinary people experience. While these concerns were already evident during the years of strong growth and good economic performance that characterised the early part of the decade, the financial and economic crisis has further amplified them.</description>
    </item>
    
    <item>
      <title>Change standard theme of ggplot</title>
      <link>/2018/10/10/change-standard-theme-of-ggplot/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/10/change-standard-theme-of-ggplot/</guid>
      <description>ggplot2 is customizeable. Frankly, one can change a heap of details - not everything probably, but a lot. Of course, one can add a theme to the ggplot call, in order to change the theme. However, a more catch-it-all approach would be to change the standard theme of ggplot itself. In this post, we’ll investigate this option.
Load some data and the right packages:
data(mtcars) library(tidyverse) Here’s the standard theme of ggplot, let’s have a look at it</description>
    </item>
    
    <item>
      <title>DataExploR: Typische Businessfragen mit R analysieren</title>
      <link>/2018/09/12/dataexplor-typische-businessfragen-mit-r-analysieren/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/12/dataexplor-typische-businessfragen-mit-r-analysieren/</guid>
      <description>In diesem Post untersuchen wir eine recht häufige Fragestellung im Bereich der Datenanalyse – die Auswertung von Umfragedaten. Umfragen sind eine gängige Angelegenheit in vielen Organisationen: man möchte wissen, ob die Kunden zufrieden sind oder was die Mitarbeiter vom Management denken. Wir werden nicht alle Aspekte der Analyse betrachten – da gibt es viel zu tun –, sondern ein paar zentrale Aspekte herausgreifen.
Laden wir zuerst ein paar nützliche Pakete:</description>
    </item>
    
    <item>
      <title>Wenn Excel aufgibt: Datenvisualisierung kann zu komplex für Excel werden</title>
      <link>/2018/09/11/wenn-excel-aufgibt-datenvisualisierung-kann-zu-komplex-f%C3%BCr-excel-werden/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/11/wenn-excel-aufgibt-datenvisualisierung-kann-zu-komplex-f%C3%BCr-excel-werden/</guid>
      <description>Ms Excel ist ein beliebtes Werkzeug der Datenanalyse, auch für Datenvisualisierung. Es gibt einige Beispiele, dass andere Werkzeuge, wie R, zu ansehnlicheren Diagrammen führen können, s. diesen Post. In diesem Post geht es um eine verwandte Frage: Gibt es Diagramme, die nicht – oder nur sehr aufwendig – mit Excel zu erstellen sind?
Die Meine Antwort lautet: Ja, die gibt es. Betrachten wir ein Beispiel.
Bayesianische Modelle visualisieren Als Hintergrund dient uns eine Analyse (s.</description>
    </item>
    
    <item>
      <title>Wenn Excel aussteigt: Datensatz umbauen zur Visualisierung</title>
      <link>/2018/09/11/wenn-excel-aussteigt-datensatz-umbauen-zur-visualisierung/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/11/wenn-excel-aussteigt-datensatz-umbauen-zur-visualisierung/</guid>
      <description>Warum R? Ich liebe Excel! Excel hat viele Vorteile; viele Menschen haben lange Jahre intensiv mit Excel gearbeitet und kennen sich sehr gut mit dieser Software aus. Warum sollte man mit einer neuen Software wie R arbeiten, wenn man Daten analysieren möchte?
Ein Grund ist, dass manche Sachen mit R leichter sind als mit Excel. Zum Beispiel dieser Fall: Sie haben einen Datensatz, in dem Ihre Umsätze pro Quartal wiedergegeben sind.</description>
    </item>
    
    <item>
      <title>Plotting a logistic regression - some considerations</title>
      <link>/2018/09/03/plotting-a-logistic-regression-some-considerations/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/03/plotting-a-logistic-regression-some-considerations/</guid>
      <description>library(mosaic) data(tips, package = &amp;quot;reshape2&amp;quot;) Recode sex:
tips %&amp;gt;% mutate(sex_n = case_when( sex == &amp;quot;Female&amp;quot; ~ 0, sex == &amp;quot;Male&amp;quot; ~ 1 )) -&amp;gt; tips2 Fit model:
glm1 &amp;lt;- glm(sex_n ~ total_bill, data = tips2, family = &amp;quot;binomial&amp;quot;) Way 1 plotModel(glm1)  Way 2 Add predictions to data frame:
tips2 %&amp;gt;% mutate(pred = predict(glm1, newdata = tips, type = &amp;quot;response&amp;quot;)) %&amp;gt;% mutate(predict_Male = pred &amp;gt; .5) -&amp;gt; tips3 Check values of predictions:</description>
    </item>
    
    <item>
      <title>Reproducible academic writing with RMarkdown - Talk at DGPs 2018</title>
      <link>/2018/09/03/reproducible-academic-writing-with-rmarkdown-talk-at-dgps-2018/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/03/reproducible-academic-writing-with-rmarkdown-talk-at-dgps-2018/</guid>
      <description>Talk at DGPs 2018.
Get slides here: http://data-se.netlify.com/slides/rmd-writing/rmd-writing_dgps2018.html.</description>
    </item>
    
    <item>
      <title>Bayesian modeling of populist party success in German federal elections - A notebook from the lab</title>
      <link>/2018/08/25/bayesian-modeling-of-populist-party-success-in-german-federal-elections/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/25/bayesian-modeling-of-populist-party-success-in-german-federal-elections/</guid>
      <description>Following up on an earlier post, we will model the voting success of the (most prominent) populist party, AfD, in the recent federal elections. This time, Bayesian modeling techniques will be used, drawing on the excellent textbook my McElreath.
Note that this post is rather a notebook of my thinking, doing, and erring. I’ve made no efforts to hide scaffolding. I think it will be confusing to the uniniate and the initiate as well …</description>
    </item>
    
    <item>
      <title>Binning and recoding with R - some recommendations</title>
      <link>/2018/08/09/binning-and-recoding-with-r-some-recommendations/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/09/binning-and-recoding-with-r-some-recommendations/</guid>
      <description>Recoding means changing the levels of a variable, for instance changing “1” to “woman” and “2” to “man”. Binning means aggregating several variable levels to one, for instance aggregating the values From “1.00 meter” to “1.60 meter” to “small_size”.
Both operations are frequently necessary in practical data analysis. In this post, we review some methods to accomplish these two tasks.
Let’s load some example data:
data(tips, package = &amp;quot;reshape2&amp;quot;) Some packages:</description>
    </item>
    
    <item>
      <title>Finding NAs in multiples columns (per row)</title>
      <link>/2018/08/09/finding-nas-in-multiples-columns-per-rows/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/09/finding-nas-in-multiples-columns-per-rows/</guid>
      <description>Assume you would like to check for missing data, but not for one column only but for several columns.
First, data and some packages:
data(mtcars) library(tidyverse) Then, let’s introduce some missing data:
mtcars[c(1,2), 1] &amp;lt;- NA mtcars[c(1, 3:4), 2] &amp;lt;- NA Don’t check columns individually Of course, you do not want to repeat yourself, and check each column individually, like this:
sum(is.na(mtcars[[1]])) #&amp;gt; [1] 2 sum(is.na(mtcars[, 1])) # same #&amp;gt; [1] 2 Neither one would like to check each row individually:</description>
    </item>
    
    <item>
      <title>test 2018-07-26</title>
      <link>/2018/07/26/test-2018-07-26/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/26/test-2018-07-26/</guid>
      <description>test</description>
    </item>
    
    <item>
      <title>Power calculation for the general linear model</title>
      <link>/2018/07/24/power-calculation-for-the-general-linear-model/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/24/power-calculation-for-the-general-linear-model/</guid>
      <description>Before conducting an experiment, one should compute the power - or, preferably, estimate the precision of the expected results. There are numerous way to achieve this, here’s one using the R package pwr.
Package pwr library(pwr) The workhorse function here is pwr.f2.test. Note that f2 refers to the effect size \(f^2\) (see here), defined as:
\[f^2 = \frac{R^2}{1-R^2}\].
See for details of the function its help page:
help(&amp;quot;pwr.f2.test&amp;quot;) pwr.f2.test(u = NULL, v = NULL, f2 = NULL, sig.</description>
    </item>
    
    <item>
      <title>How to prepare data for a gantt diagram</title>
      <link>/2018/07/05/how-to-prepare-data-for-a-gantt-diagram/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/05/how-to-prepare-data-for-a-gantt-diagram/</guid>
      <description>There’s the new cool world of project management - agile, scrumbling, cool. There’s the old sluggish way of project management using stuff like gantt diagrams. Let’s stick to the old world and come up with a gantt diagram.
The gant diagram itself is no big deal. Just some horizontal lines referring to dates. Somewhat more interesting is to populate a raw data frame in a way that allows for convenient plotting.</description>
    </item>
    
    <item>
      <title>Work with bibtex bib files like a pro</title>
      <link>/2018/07/05/work-with-bibtex-bib-files-like-a-pro/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/05/work-with-bibtex-bib-files-like-a-pro/</guid>
      <description>Recently, I had to curate a list of publications for our institution. Where’s the point? One might ask. Let’s leave aside that a number of colleagues do not use citation management software to work with their publications. They just hack the citation, if and when needed, in some word files. Done. Fair enough, unless someone tries to come up with a list of all the publication of that institution. In that case, the curator will need some structured data, otherwise he or she will end up copy-pasting the rest of the day.</description>
    </item>
    
    <item>
      <title>Some musings on the logistic map</title>
      <link>/2018/06/19/some-musings-on-the-logistic-map/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/19/some-musings-on-the-logistic-map/</guid>
      <description>The logistic map is a well-known and simple growth model that is defined by the iterative equation
\[x_{t+1} = 4rx_t(1-t_t)\],
where \(r\) is a parameter that can be thought of as a fertility and reproduction rate of the population. The allowed values of \(x\) range between 0 an 1 inclusively, where 0 means the population is extinct. The maximum of 1 can be interpreted as the ecological carrying capacity of the system.</description>
    </item>
    
    <item>
      <title>Visualizing mean values between two groups  - the tidyverse way</title>
      <link>/2018/06/10/visualizing-summary-statistics-the-tidyverse-way/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/10/visualizing-summary-statistics-the-tidyverse-way/</guid>
      <description>A frequent job in data visualizing is to present summary statistics. In this post, I show one way to plot mean values between groups using the tidyverse approach in comparison to the mosaic way.
library(tidyverse) data(mtcars) library(mosaic) library(knitr) library(sjmisc) library(sjPlot) Visualizing mean values between two groups First, let’s compute the mean hp for automatic cars (am == 0) vs. manual cars (am == 1).
mtcars %&amp;gt;% group_by(am) %&amp;gt;% summarise(hp_am = mean(hp)) -&amp;gt; hp_am Now just hand over this data frame of summarized data to ggplot:</description>
    </item>
    
    <item>
      <title>Playing around with geo mapping: combining demographic data with spatial data</title>
      <link>/2018/05/28/playing-around-with-geo-mapping-combining-demographic-data-with-spatial-data/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/28/playing-around-with-geo-mapping-combining-demographic-data-with-spatial-data/</guid>
      <description>In this post, we will play around with some basic geo mapping. More preciseyl, we will explore some easy ways to plot a choropleth map.
First, let’s load some geo data from Bundeswahlleiter, and combine it with some socio demographic data from the same source.
Preparation Let’s load some packages:
library(tidyverse) ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.1 library(sf) library(viridis) suppressPackageStartupMessages(library(googleVis)) Geo data:
my_path_wahlkreise &amp;lt;- &amp;quot;~/Documents/datasets/geo_maps/btw17_geometrie_wahlkreise_shp/Geometrie_Wahlkreise_19DBT.shp&amp;quot; file.</description>
    </item>
    
    <item>
      <title>Simulating a correlation matrix.</title>
      <link>/2018/05/18/simulating-a-correlation-matrix/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/18/simulating-a-correlation-matrix/</guid>
      <description>Simulation based inference is a powerful tool as it lets you derive population estimates without having to solve difficult equations. As a more advanced example for simulation, consider the following situation. You are interested in the correlation of air time and delay of planes. More precisely you assume that this correlation is the same for different carriers (airlines). In other words, the (absolute) difference between all different pairs of correlation coefficient is zero, according to the hypothesis.</description>
    </item>
    
    <item>
      <title>Why is the sample mean a good point estimator of the population mean? A simulation and some thoughts.</title>
      <link>/2018/05/18/why-is-the-sample-mean-a-good-point-estimator-of-the-population-mean-a-simulation-and-some-thoughts/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/18/why-is-the-sample-mean-a-good-point-estimator-of-the-population-mean-a-simulation-and-some-thoughts/</guid>
      <description>It is frequently stated that the sample mean is a good or even the best point estimator of the according population value. But why is that? In this post we are trying to get an intuition by using simulation inference methods.
Assume you played throwing coins with some one at some dark corner. “Some one” throws the coin 10 times, and wins 8 times (the guy was betting on heads, but that’s only for the sake of the story).</description>
    </item>
    
    <item>
      <title>Quick intro to geo plotting</title>
      <link>/2018/05/17/quick-intro-to-geo-plotting/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/17/quick-intro-to-geo-plotting/</guid>
      <description>Geo plotting can be simple; at least in its basic form. Let’s review an example using data from GADM.
GADM provides maps for many (all?) countries of the world; not only the country borders but even administrative border lines an a finder scale.
It comes very handy that the map (geo) can be downloaded as R data files:
data_path &amp;lt;- &amp;quot;https://biogeo.ucdavis.edu/data/gadm3.6/Rsf/gadm36_DEU_2_sf.rds&amp;quot; Load some packages:
library(sf) library(tidyverse) library(downloader) Download the maps data:</description>
    </item>
    
    <item>
      <title>One-way ANOVA power analysis</title>
      <link>/2018/04/11/one-way-anova-power-analysis/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/11/one-way-anova-power-analysis/</guid>
      <description>Computing or estimating power is a very useful procedure in order to weigh the reliability of study results.
One frequent procedure in inferential statistics is the ANOVA, with the simplest form being the one-way ANOVA. This post shows how to compute power for this test.
What’s the effect size? The first thing to not is that there is no such thing as “power” - in the sense that a sample or a test would have “its power”.</description>
    </item>
    
    <item>
      <title>Parse libraries from R project</title>
      <link>/2018/04/11/parse-libraries-from-r-project/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/11/parse-libraries-from-r-project/</guid>
      <description>Having written a larger R project is may be of interest which packages have been used. As I did not find a read-to-use package, a colleague of mine - Norman Markgraf - came up with a nice solution. In this post, I build on his solution to provide a function that suits my needs of today:
@Norman: Thanks for your great idea!
First, some libraries:
library(tidyverse) library(bibtex) library(testthat) Then, here is some path of an R project where we want to parse all rmd files:</description>
    </item>
    
    <item>
      <title>Metrics for readability of slide decks for teaching</title>
      <link>/2018/04/09/metrics-for-readability-of-slide-decks-for-teaching/</link>
      <pubDate>Mon, 09 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/09/metrics-for-readability-of-slide-decks-for-teaching/</guid>
      <description>Some thoughts on the “quality” of slide decks used in teaching: How many visuals are there? How much text is squeezed on a slide? What’s the average word and sentence length? How much buzz words and complicated jargon is present?
Let’s have an initial look at some meaures in that regard. Hey, this post is just playing around a little. We will work with this slide deck, published under CC-BY 3, with parts as GNU - so all “open” in short.</description>
    </item>
    
    <item>
      <title>Visualisation of interaction for the logistic regression</title>
      <link>/2018/04/02/visualisation-of-interaction-for-logistic-regression/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/02/visualisation-of-interaction-for-logistic-regression/</guid>
      <description>In this post we are plotting an interaction for a logistic regression. Interaction per se is a concept difficult to grasp; for a GLM it may be even more difficult especially for continuous variables’ interaction. Plotting helps to better or more easy grasp what a model tries to tell us.
First, load some packages.
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.</description>
    </item>
    
    <item>
      <title>How to cite in markdown, a short primer</title>
      <link>/2018/03/26/how-to-cite-in-markdown-a-short-primer/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/26/how-to-cite-in-markdown-a-short-primer/</guid>
      <description>I would never write a paper again using Word - except I would be forced, too, what will happen, I think. But similarly, I don’t want to write papers using Latex - too many curly braces.
Best of both worlds: Markdown. Comes with “builtin” R.
Here’s an example how to do scholarly citation in markdown.
In-Text citation Use this notation, to cite some book or paper or whatever:
The Good, the Bad, and the Ugly face similarly difficulties [@thedude2012].</description>
    </item>
    
    <item>
      <title>Why &#34;n-1&#34; in empirical variance? A simulation.</title>
      <link>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</guid>
      <description>It is well-known that the empirical variance underestimates the population variance. Specifically, the empirical variance is defined as: \(var_{emp} = \frac{\sum_i (x_i - \bar{x})^2}{n-1}\). But why \(n-1\), why not just \(n\), as intuition (of some) dictates? Put shortly, as the variance of a sample tends to underestimate the population variance we have to inflate it artificially, to enlarge it, that’s why we do put a smaller number (the “n-1”) in the denominator, resulting in a larger value of the whole fraction.</description>
    </item>
    
    <item>
      <title>Tangible data of normal distributed data</title>
      <link>/2018/03/16/tangible-data-of-normal-distributed-data/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/16/tangible-data-of-normal-distributed-data/</guid>
      <description>A classical example for a normally distributed variable is height. However, I kept on looking for data as to the mean and sd for some populations, such as Germany. Now I found some reliably looking data here.
We will not question whether the assumption of normality holds, we just assume it.
In the source, we can read that in Germany, the adult men population has the following parameters:
mean: 174cm</description>
    </item>
    
    <item>
      <title>Map students to presentation slots</title>
      <link>/2018/03/11/map-students-to-presentation-slots/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/11/map-students-to-presentation-slots/</guid>
      <description>As a teacher, I not only teach but also assess the achievements of students. One example of a typical student assignments is a presentation. You know, powerpoint slides and stuff.
For that purpose, I often need to map students to one of several time slots. Here’s the R code I use for that purpose.
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.</description>
    </item>
    
    <item>
      <title>Intuition to Simpson&#39;s paradox</title>
      <link>/2018/03/09/intuition-to-simpson-s-paradox/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/09/intuition-to-simpson-s-paradox/</guid>
      <description>Say, you have to choose between two doctors (Anna and Berta). To decide which one is better, you check their success rates. Suppose that they deal with two conditions (Coolities and Dummities). So let’s compare their success rate for each of the two conditions (and the total success rate):
This is the proportion of healing (success) of the first doctor, Dr. Anna for each of the two conditions:
 Coolities: 7 out of 8 patients are healed from Coolities Dummieties: 1 out of 2 patients are healed from Dummities  This is the proportion of healing (success) of the first doctor, Dr.</description>
    </item>
    
    <item>
      <title>How to create columns in a dataframe in R</title>
      <link>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</guid>
      <description>Note that we will use this library for this post:
library(dplyr) ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.1 ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union By the way, loading mosaic, will load dplyr too.
One of the major data wrangling activities (in R and elsewhere) is to create a new column in a data frame.</description>
    </item>
    
    <item>
      <title>Simulate p-hacking - adding observations</title>
      <link>/2018/01/24/simulate-p-hacking-adding-observations/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/24/simulate-p-hacking-adding-observations/</guid>
      <description>Let’s simulate p-values as a funtion of sample size. We assume that some researcher collects one data point, computes the p-value, and repeats until p-value falls below some arbitrary threshold. Oh and yes, there is no real effect. For the sake of spending the budget, assume that our researcher collects a sample size of \(n=100\).
This idea stems from this great article False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant; cf.</description>
    </item>
    
    <item>
      <title>Visualizing a logistic regression the easy way</title>
      <link>/2018/01/23/visualizing-a-logistic-regression-the-easy-way/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/23/visualizing-a-logistic-regression-the-easy-way/</guid>
      <description>Let’s visualize a GLM (logistic regression).
First laod some data:
data(tips, package = &amp;quot;reshape2&amp;quot;) Compute a glm:
glm_tips &amp;lt;- glm(sex ~ tip, data = tips, family = &amp;quot;binomial&amp;quot;) Plot the model using mosaic:
library(mosaic) ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.1 plotModel(glm_tips) The curve does not look really s-typed (ogive) but that’s ok because the data suggest not a strong trend. The plot is not very beautiful either, but hey - it’s quick to produce 😁.</description>
    </item>
    
    <item>
      <title>Zusammenhang von Lernen und Noten im Statistikunterricht</title>
      <link>/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</guid>
      <description>Führt Lernen zu besseren Noten? Eigene Erfahrung und allgemeiner Konsens stimmen dem zu; zumindest schadet Lernen des Stoffes nicht und hilft oft, gute Noten bei einer Prüfung zu diesem Stoff zu erzielen. Aber welche Belege, wissenschaftliche Belege gibt es dazu? An unserer Hochschule, die FOM, haben wir eine kleine Untersuchung zu dieser Frage durchgeführt. Genauer gesagt haben wir unseren Studierenden einen Statistik-Test vorlegt und gefagt, wie sehr sie sich für diesen Test vorbereitet hätten.</description>
    </item>
    
    <item>
      <title>A p-value picture</title>
      <link>/2017/11/29/a-p-value-picture/</link>
      <pubDate>Wed, 29 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/29/a-p-value-picture/</guid>
      <description>Much ado and to say about the p-value. Let me add one more point; actually not really from myself, but from Diez, Barr, and Cetinkaya-Rundel (2012), p. 189; good book in one is looking for “orthodox” statistics.
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.6 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R</title>
      <link>/2017/11/28/textmining-grundlagen/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/28/textmining-grundlagen/</guid>
      <description>Lernziele:
  - Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &amp;#39;tidy text dataframe&amp;#39; ist. - Sie können Worthäufigkeiten auszählen. - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren. In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages &amp;gt; Install.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R - Teil 2</title>
      <link>/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</guid>
      <description>In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen library(skimr) # Überblicksstatistiken  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.
 ## ## Attaching package: &amp;#39;knitr&amp;#39; ## The following object is masked from &amp;#39;package:skimr&amp;#39;: ## ## kable Aus dem letzten Post Daten einlesen:
osf_link &amp;lt;- paste0(&amp;quot;https://osf.</description>
    </item>
    
    <item>
      <title>Dummy variables and regression</title>
      <link>/2017/11/27/dummy-variables-and-regression/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/dummy-variables-and-regression/</guid>
      <description>For modeling cause-effect relationships, linear regression is among the most typically used methods.
Take, for example, the idea that the Gross Domestic Product (GDP) drives religiosity. Of course, we should have a strong theory that defends this choice and this directionality. Without a convincing theory it may be argued that the cause-relationship is the other way round or complete different (ie., some third variable accounts for any association between GDP and religiosity).</description>
    </item>
    
    <item>
      <title>Interactive diagrams in lieu of shiny?</title>
      <link>/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</guid>
      <description>One frequent use of the Shiny server software is displaying interactive data diagrams. The pro of using Shiny is the great flexibility; much more than “just graphics” can be done. Basically Shiny provides a flexible GUI for your R program. But if you simply aiming at displaying or exploring some data interactively, a much simplor approach may do it for you; there are some nice libraries available in R for that.</description>
    </item>
    
    <item>
      <title>My favorite stats text book</title>
      <link>/2017/11/27/my-favorite-stats-text-book/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/my-favorite-stats-text-book/</guid>
      <description>Some thoughts how my favorite applied stats text book would look like. I am looking at eg., business fields such as MBA as consumers.
My ideal applied stats text book is case study oriented (“Assume you would like to predict which movie will score highest next year based on some movie characteristics you know”)
 makes use of recent data analytics techniques such as tree based methods (Random Forests) or Shrinkage models (Lasso)</description>
    </item>
    
    <item>
      <title>Use case for purrr::map</title>
      <link>/2017/11/23/use-case-for-purrr-map/</link>
      <pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/23/use-case-for-purrr-map/</guid>
      <description> library(tidyverse) ## ── Attaching packages ──────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.8 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ─────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() d &amp;lt;- data_frame( id = c(1,1,1,1,1,1,2,2,3,3,3,4,1,2,2) ) d$id %&amp;gt;% map </description>
    </item>
    
    <item>
      <title>Compute effect sizes with R. A primer.</title>
      <link>/2017/11/21/compute-effect-sizes-with-r-a-primer/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/compute-effect-sizes-with-r-a-primer/</guid>
      <description>A typical “cook book recipe” for doing data analysis is an applied stats course is:
report descriptive statistics plot some nice diagrams test hypothesis report effect sizes  Let’s have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &amp;quot;nycflights13&amp;quot;) This post will be tidyverse-driven.
library(tidyverse) library(skimr) library(mosaic) Let’s compute some summaries:
flights %&amp;gt;% select(arr_delay) %&amp;gt;% skim #&amp;gt; Skim summary statistics #&amp;gt; n obs: 336776 #&amp;gt; n variables: 1 #&amp;gt; #&amp;gt; Variable type: numeric #&amp;gt; variable missing complete n mean sd p0 p25 p50 p75 p100 #&amp;gt; arr_delay 9430 327346 336776 6.</description>
    </item>
    
    <item>
      <title>Get your stats result in a table easily</title>
      <link>/2017/11/21/get-your-stats-result-in-a-table-easily/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/get-your-stats-result-in-a-table-easily/</guid>
      <description>Having computed some staticis, one would like to display them. Either in a figure, on in a table, that’s the two typical ways.
Let’s explore some helper functions to get your stats to a table easily.
A nice overview on packages can be found here.
Let’s have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &amp;quot;nycflights13&amp;quot;) This post will be tidyverse-driven:</description>
    </item>
    
    <item>
      <title>Pass multiple functions and arguments to purrr::map</title>
      <link>/2017/11/21/pass-multiple-functions-and-arguments-to-purrr-map/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/pass-multiple-functions-and-arguments-to-purrr-map/</guid>
      <description>I just run in the following problem: I wanted to map multiple functions to multiple columns, and I needed to pass some arguments to this map call. Sound theoretical, I know. Consider this example:
library(tidyverse) ## ── Attaching packages ──────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.8 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.</description>
    </item>
    
    <item>
      <title>Great dataviz examples in rstats</title>
      <link>/2017/11/20/great-dataviz-examples-in-rstats/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/20/great-dataviz-examples-in-rstats/</guid>
      <description>Here come some stunning examples of data visualizations, all built with R. R code of each diagram is available at the source. Enjoy! #beautiful.
UPDATE: I&amp;rsquo;ve included links to the R source!
Plotting geo maps along with subplots in ggplot2 I like this one by Ilya Kashnitsky:
Similarly, by the same author:
Source
Great work, @ikashnitsky!
Cirlize (Chord) diagrams Plotting association in a circular form yields aesthetic examples of diagrams, see the following examples</description>
    </item>
    
    <item>
      <title>Mapping foreigner ratio to AfD election results in the German Wahlkreise</title>
      <link>/2017/10/22/mapping-foreigner-ratio-to-afd-election-results-in-the-german-wahlkreise/</link>
      <pubDate>Sun, 22 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/22/mapping-foreigner-ratio-to-afd-election-results-in-the-german-wahlkreise/</guid>
      <description>In a previous post, we have shed some light on the idea that populism - as manifested in AfD election results - is associated with socioeconomic deprivation, be it subjective or objective. We found some supporting pattern in the data, although that hypothesis is far from being complete; ie., most of the variance remained unexplained.
In this post, we test the hypothesis that AfD election results are negatively associated with the proportion of foreign nationals in a Wahlkreis.</description>
    </item>
    
    <item>
      <title>Two r plots side by sind in a Rmd-File - UPDATE</title>
      <link>/2017/10/12/two-r-plots-side-by-sind-in-a-rmd-file/</link>
      <pubDate>Thu, 12 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/12/two-r-plots-side-by-sind-in-a-rmd-file/</guid>
      <description>UPDATE 2018-12-03
Thanks to a comment by Katharina Hees and Joyce, I know know how to plot two images side by side in an Rmd file.
I kept wondering who to plot two R plots side by side (ie., in one “row”) in a .Rmd chunk. Here’s a way, well actually a number of ways, some good, some … not.
library(tidyverse) library(gridExtra) library(grid) library(png) library(downloader) library(grDevices) data(mtcars) Plots from ggplot Say, you have two plots from ggplot2, and you would like them to put them next to each other, side by side (not underneath each other):</description>
    </item>
    
    <item>
      <title>Crashkurs Datenanalyse mit R</title>
      <link>/2017/05/16/crashkurs/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/16/crashkurs/</guid>
      <description>Nicht jeder liebt Datenanalyse und Statistik… in gleichem Maße. Das ist zumindest meine Erfahrung aus dem Unterricht :neckbeard: :fire:. Crashkurse zu R sind vergleichbar zu Crahskursen zu Französisch - kann man machen, aber es sollte die Maxime gelten “If everything else fails”.
Dieser Crashkurs ist für Studierende oder Anfänger der Datenanalyse gedacht, die in kurzer Zeit einen verzweifelten Versuch … äh … einen grundständigen Überblick über die Datenanalyse erwerben wollen.</description>
    </item>
    
    <item>
      <title>Deriving the logits for logistic regression</title>
      <link>/2017/05/06/deriving-the-logits-for-logistic-regression/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/06/deriving-the-logits-for-logistic-regression/</guid>
      <description>The logistic regression is an incredible useful tool, partly because binary outcomes are so frequent in live (“she loves me - she doesn’t love me”). In parts because we can make use of well-known “normal” regression instruments.
But the formula of logistic regression appears opaque to many (beginners or those with not so much math background).
Let’s try to shed some light on the formula by discussing some accessible explanation on how to derive the formula.</description>
    </item>
    
  </channel>
</rss>