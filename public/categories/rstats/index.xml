<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rstats on Data Se</title>
    <link>/categories/rstats/</link>
    <description>Recent content in Rstats on Data Se</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/rstats/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Some musings on the logistic map</title>
      <link>/2018/06/19/some-musings-on-the-logistic-map/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/19/some-musings-on-the-logistic-map/</guid>
      <description>The logistic map is a well-known and simple growth model that is defined by the iterative equation
\[x_{t+1} = 4rx_t(1-t_t)\],
where \(r\) is a parameter that can be thought of as a fertility and reproduction rate of the population. The allowed values of \(x\) range between 0 an 1 inclusively, where 0 means the population is extinct. The maximum of 1 can be interpreted as the ecological carrying capacity of the system.</description>
    </item>
    
    <item>
      <title>Visualizing mean values between two groups  - the tidyverse way</title>
      <link>/2018/06/10/visualizing-summary-statistics-the-tidyverse-way/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/10/visualizing-summary-statistics-the-tidyverse-way/</guid>
      <description>A frequent job in data visualizing is to present summary statistics. In this post, I show one way to plot mean values between groups using the tidyverse approach in comparison to the mosaic way.
library(tidyverse) data(mtcars) library(mosaic) library(knitr) library(sjmisc) library(sjPlot) Visualizing mean values between two groups First, let’s compute the mean hp for automatic cars (am == 0) vs. manual cars (am == 1).
mtcars %&amp;gt;% group_by(am) %&amp;gt;% summarise(hp_am = mean(hp)) -&amp;gt; hp_am Now just hand over this data frame of summarized data to ggplot:</description>
    </item>
    
    <item>
      <title>Playing around with geo mapping: combining demographic data with spatial data</title>
      <link>/2018/05/28/playing-around-with-geo-mapping-combining-demographic-data-with-spatial-data/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/28/playing-around-with-geo-mapping-combining-demographic-data-with-spatial-data/</guid>
      <description>In this post, we will play around with some basic geo mapping. More preciseyl, we will explore some easy ways to plot a choropleth map.
First, let’s load some geo data (Bundeswahlleiter, 2017), and combine it with some socio demographic data from the same source (Bundeswahlleiter, 2017).
Preparation Let’s load some packages:
library(tidyverse) library(sf) library(viridis) suppressPackageStartupMessages(library(googleVis)) Geo data:
my_path_wahlkreise &amp;lt;- &amp;quot;~/Documents/datasets/geo_maps/btw17_geometrie_wahlkreise_shp/Geometrie_Wahlkreise_19DBT.shp&amp;quot; file.exists(my_path_wahlkreise) ## [1] TRUE socio demographic data:
unemp_file &amp;lt;- &amp;quot;~/Documents/datasets/Strukturdaten_De/btw17_Strukturdaten-utf8.</description>
    </item>
    
    <item>
      <title>Simulating a correlation matrix.</title>
      <link>/2018/05/18/simulating-a-correlation-matrix/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/18/simulating-a-correlation-matrix/</guid>
      <description>Simulation based inference is a powerful tool as it lets you derive population estimates without having to solve difficult equations. As a more advanced example for simulation, consider the following situation. You are interested in the correlation of air time and delay of planes. More precisely you assume that this correlation is the same for different carriers (airlines). In other words, the (absolute) difference between all different pairs of correlation coefficient is zero, according to the hypothesis.</description>
    </item>
    
    <item>
      <title>Why is the sample mean a good point estimator of the population mean? A simulation and some thoughts.</title>
      <link>/2018/05/18/why-is-the-sample-mean-a-good-point-estimator-of-the-population-mean-a-simulation-and-some-thoughts/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/18/why-is-the-sample-mean-a-good-point-estimator-of-the-population-mean-a-simulation-and-some-thoughts/</guid>
      <description>It is frequently stated that the sample mean is a good or even the best point estimator of the according population value. But why is that? In this post we are trying to get an intuition by using simulation inference methods.
Assume you played throwing coins with some one at some dark corner. “Some one” throws the coin 10 times, and wins 8 times (the guy was betting on heads, but that’s only for the sake of the story).</description>
    </item>
    
    <item>
      <title>Quick intro to geo plotting</title>
      <link>/2018/05/17/quick-intro-to-geo-plotting/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/17/quick-intro-to-geo-plotting/</guid>
      <description>Geo plotting can be simple; at least in its basic form. Let’s review an example using data from GADM.
GADM provides maps for many (all?) countries of the world; not only the country borders but even administrative border lines an a finder scale.
It comes very handy that the map (geo) can be downloaded as R data files:
data_path &amp;lt;- &amp;quot;https://biogeo.ucdavis.edu/data/gadm3.6/Rsf/gadm36_DEU_2_sf.rds&amp;quot; Load some packages:
library(sf) library(tidyverse) library(downloader) Download the maps data:</description>
    </item>
    
    <item>
      <title>One-way ANOVA power analysis</title>
      <link>/2018/04/11/one-way-anova-power-analysis/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/11/one-way-anova-power-analysis/</guid>
      <description>Computing or estimating power is a very useful procedure in order to weigh the reliability of study results.
One frequent procedure in inferential statistics is the ANOVA, with the simplest form being the one-way ANOVA. This post shows how to compute power for this test.
What’s the effect size? The first thing to not is that there is no such thing as “power” - in the sense that a sample or a test would have “its power”.</description>
    </item>
    
    <item>
      <title>Parse libraries from R project</title>
      <link>/2018/04/11/parse-libraries-from-r-project/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/11/parse-libraries-from-r-project/</guid>
      <description>Having written a larger R project is may be of interest which packages have been used. As I did not find a read-to-use package, a colleague of mine - Norman Markgraf - came up with a nice solution. In this post, I build on his solution to provide a function that suits my needs of today:
@Norman: Thanks for your great idea!
First, some libraries:
library(tidyverse) library(bibtex) library(testthat) Then, here is some path of an R project where we want to parse all rmd files:</description>
    </item>
    
    <item>
      <title>Metrics for readability of slide decks for teaching</title>
      <link>/2018/04/09/metrics-for-readability-of-slide-decks-for-teaching/</link>
      <pubDate>Mon, 09 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/09/metrics-for-readability-of-slide-decks-for-teaching/</guid>
      <description>Some thoughts on the “quality” of slide decks used in teaching: How many visuals are there? How much text is squeezed on a slide? What’s the average word and sentence length? How much buzz words and complicated jargon is present?
Let’s have an initial look at some meaures in that regard. Hey, this post is just playing around a little. We will work with this slide deck, published under CC-BY 3, with parts as GNU - so all “open” in short.</description>
    </item>
    
    <item>
      <title>Visualisation of interaction for the logistic regression</title>
      <link>/2018/04/02/visualisation-of-interaction-for-logistic-regression/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/02/visualisation-of-interaction-for-logistic-regression/</guid>
      <description>In this post we are plotting an interaction for a logistic regression. Interaction per se is a concept difficult to grasp; for a GLM it may be even more difficult especially for continuous variables’ interaction. Plotting helps to better or more easy grasp what a model tries to tell us.
First, load some packages.
library(tidyverse) ## ── Attaching packages ──────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.4 ## ✔ tibble 1.</description>
    </item>
    
    <item>
      <title>How to cite in markdown, a short primer</title>
      <link>/2018/03/26/how-to-cite-in-markdown-a-short-primer/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/26/how-to-cite-in-markdown-a-short-primer/</guid>
      <description>I would never write a paper again using Word - except I would be forced, too, what will happen, I think. But similarly, I don’t want to write papers using Latex - too many curly braces.
Best of both worlds: Markdown. Comes with “builtin” R.
Here’s an example how to do scholarly citation in markdown.
In-Text citation Use this notation, to cite some book or paper or whatever:
The Good, the Bad, and the Ugly face similarly difficulties [@thedude2012].</description>
    </item>
    
    <item>
      <title>Why &#34;n-1&#34; in empirical variance? A simulation.</title>
      <link>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</guid>
      <description>It is well-known that the empirical variance underestimates the population variance. Specifically, the empirical variance is defined as: \(var_{emp} = \frac{\sum_i (x_i - \bar{x})^2}{n-1}\). But why \(n-1\), why not just \(n\), as intuition (of some) dictates? Put shortly, as the variance of a sample tends to underestimate the population variance we have to inflate it artificially, to enlarge it, that’s why we do put a smaller number (the “n-1”) in the denominator, resulting in a larger value of the whole fraction.</description>
    </item>
    
    <item>
      <title>Tangible data of normal distributed data</title>
      <link>/2018/03/16/tangible-data-of-normal-distributed-data/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/16/tangible-data-of-normal-distributed-data/</guid>
      <description>A classical example for a normally distributed variable is height. However, I kept on looking for data as to the mean and sd for some populations, such as Germany. Now I found some reliably looking data here.
We will not question whether the assumption of normality holds, we just assume it.
In the source, we can read that in Germany, the adult men population has the following parameters:
mean: 174cm</description>
    </item>
    
    <item>
      <title>Map students to presentation slots</title>
      <link>/2018/03/11/map-students-to-presentation-slots/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/11/map-students-to-presentation-slots/</guid>
      <description>As a teacher, I not only teach but also assess the achievements of students. One example of a typical student assignments is a presentation. You know, powerpoint slides and stuff.
For that purpose, I often need to map students to one of several time slots. Here’s the R code I use for that purpose.
library(tidyverse) ## ── Attaching packages ──────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.4 ## ✔ tibble 1.</description>
    </item>
    
    <item>
      <title>Intuition to Simpson&#39;s paradox</title>
      <link>/2018/03/09/intuition-to-simpson-s-paradox/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/09/intuition-to-simpson-s-paradox/</guid>
      <description>Say, you have to choose between two doctors (Anna and Berta). To decide which one is better, you check their success rates. Suppose that they deal with two conditions (Coolities and Dummities). So let’s compare their success rate for each of the two conditions (and the total success rate):
This is the proportion of healing (success) of the first doctor, Dr. Anna for each of the two conditions:
 Coolities: 7 out of 8 patients are healed from Coolities Dummieties: 1 out of 2 patients are healed from Dummities  This is the proportion of healing (success) of the first doctor, Dr.</description>
    </item>
    
    <item>
      <title>How to create columns in a dataframe in R</title>
      <link>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</guid>
      <description>Note that we will use this library for this post:
library(dplyr) ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union By the way, loading mosaic, will load dplyr too.
One of the major data wrangling activities (in R and elsewhere) is to create a new column in a data frame.</description>
    </item>
    
    <item>
      <title>Simulate p-hacking - adding observations</title>
      <link>/2018/01/24/simulate-p-hacking-adding-observations/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/24/simulate-p-hacking-adding-observations/</guid>
      <description>Let’s simulate p-values as a funtion of sample size. We assume that some researcher collects one data point, computes the p-value, and repeats until p-value falls below some arbitrary threshold. Oh and yes, there is no real effect. For the sake of spending the budget, assume that our researcher collects a sample size of \(n=100\).
This idea stems from this great article False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant; cf.</description>
    </item>
    
    <item>
      <title>Visualizing a logistic regression the easy way</title>
      <link>/2018/01/23/visualizing-a-logistic-regression-the-easy-way/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/23/visualizing-a-logistic-regression-the-easy-way/</guid>
      <description>Let’s visualize a GLM (logistic regression).
First laod some data:
data(tips, package = &amp;quot;reshape2&amp;quot;) Compute a glm:
glm_tips &amp;lt;- glm(sex ~ tip, data = tips, family = &amp;quot;binomial&amp;quot;) Plot the model using mosaic:
library(mosaic) plotModel(glm_tips) The curve does not look really s-typed (ogive) but that’s ok because the data suggest not a strong trend. The plot is not very beautiful either, but hey - it’s quick to produce 😁.</description>
    </item>
    
    <item>
      <title>Zusammenhang von Lernen und Noten im Statistikunterricht</title>
      <link>/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</guid>
      <description>Führt Lernen zu besseren Noten? Eigene Erfahrung und allgemeiner Konsens stimmen dem zu; zumindest schadet Lernen des Stoffes nicht und hilft oft, gute Noten bei einer Prüfung zu diesem Stoff zu erzielen. Aber welche Belege, wissenschaftliche Belege gibt es dazu? An unserer Hochschule, die FOM, haben wir eine kleine Untersuchung zu dieser Frage durchgeführt. Genauer gesagt haben wir unseren Studierenden einen Statistik-Test vorlegt und gefagt, wie sehr sie sich für diesen Test vorbereitet hätten.</description>
    </item>
    
    <item>
      <title>A p-value picture</title>
      <link>/2017/11/29/a-p-value-picture/</link>
      <pubDate>Wed, 29 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/29/a-p-value-picture/</guid>
      <description>Much ado and to say about the p-value. Let me add one more point; actually not really from myself, but from Diez, Barr, and Cetinkaya-Rundel (2012), p. 189; good book in one is looking for “orthodox” statistics.
library(tidyverse) ## ── Attaching packages ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.5 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R</title>
      <link>/2017/11/28/textmining-grundlagen/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/28/textmining-grundlagen/</guid>
      <description>Lernziele:
  - Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &amp;#39;tidy text dataframe&amp;#39; ist. - Sie können Worthäufigkeiten auszählen. - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren. In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R - Teil 2</title>
      <link>/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</guid>
      <description>In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen library(skimr) # Überblicksstatistiken  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.
 ## ## Attaching package: &amp;#39;knitr&amp;#39; ## The following object is masked from &amp;#39;package:skimr&amp;#39;: ## ## kable Aus dem letzten Post Daten einlesen:
osf_link &amp;lt;- paste0(&amp;quot;https://osf.io/b35r7/?action=download&amp;quot;) afd &amp;lt;- read_csv(osf_link) ## Parsed with column specification: ## cols( ## page = col_integer(), ## content = col_character() ## ) Aus breit mach lang:</description>
    </item>
    
    <item>
      <title>Dummy variables and regression</title>
      <link>/2017/11/27/dummy-variables-and-regression/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/dummy-variables-and-regression/</guid>
      <description>For modeling cause-effect relationships, linear regression is among the most typically used methods.
Take, for example, the idea that the Gross Domestic Product (GDP) drives religiosity. Of course, we should have a strong theory that defends this choice and this directionality. Without a convincing theory it may be argued that the cause-relationship is the other way round or complete different (ie., some third variable accounts for any association between GDP and religiosity).</description>
    </item>
    
    <item>
      <title>Interactive diagrams in lieu of shiny?</title>
      <link>/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</guid>
      <description>One frequent use of the Shiny server software is displaying interactive data diagrams. The pro of using Shiny is the great flexibility; much more than “just graphics” can be done. Basically Shiny provides a flexible GUI for your R program. But if you simply aiming at displaying or exploring some data interactively, a much simplor approach may do it for you; there are some nice libraries available in R for that.</description>
    </item>
    
    <item>
      <title>My favorite stats text book</title>
      <link>/2017/11/27/my-favorite-stats-text-book/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/my-favorite-stats-text-book/</guid>
      <description>Some thoughts how my favorite applied stats text book would look like. I am looking at eg., business fields such as MBA as consumers.
My ideal applied stats text book is case study oriented (“Assume you would like to predict which movie will score highest next year based on some movie characteristics you know”)
 makes use of recent data analytics techniques such as tree based methods (Random Forests) or Shrinkage models (Lasso)</description>
    </item>
    
    <item>
      <title>Use case for purrr::map</title>
      <link>/2017/11/23/use-case-for-purrr-map/</link>
      <pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/23/use-case-for-purrr-map/</guid>
      <description>library(tidyverse) ## ── Attaching packages ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.5 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() d &amp;lt;- data_frame( id = c(1,1,1,1,1,1,2,2,3,3,3,4,1,2,2) ) d$id %&amp;gt;% map </description>
    </item>
    
    <item>
      <title>Compute effect sizes with R. A primer.</title>
      <link>/2017/11/21/compute-effect-sizes-with-r-a-primer/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/compute-effect-sizes-with-r-a-primer/</guid>
      <description>A typical “cook book recipe” for doing data analysis is an applied stats course is:
report descriptive statistics plot some nice diagrams test hypothesis report effect sizes  Let’s have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &amp;quot;nycflights13&amp;quot;) This post will be tidyverse-driven.
library(tidyverse) library(skimr) library(mosaic) Let’s compute some summaries:
flights %&amp;gt;% select(arr_delay) %&amp;gt;% skim #&amp;gt; Skim summary statistics #&amp;gt; n obs: 336776 #&amp;gt; n variables: 1 #&amp;gt; #&amp;gt; Variable type: numeric #&amp;gt; variable missing complete n mean sd p0 p25 p50 p75 p100 #&amp;gt; arr_delay 9430 327346 336776 6.</description>
    </item>
    
    <item>
      <title>Get your stats result in a table easily</title>
      <link>/2017/11/21/get-your-stats-result-in-a-table-easily/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/get-your-stats-result-in-a-table-easily/</guid>
      <description>Having computed some staticis, one would like to display them. Either in a figure, on in a table, that’s the two typical ways.
Let’s explore some helper functions to get your stats to a table easily.
A nice overview on packages can be found here.
Let’s have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &amp;quot;nycflights13&amp;quot;) This post will be tidyverse-driven:</description>
    </item>
    
    <item>
      <title>Pass multiple functions and arguments to purrr::map</title>
      <link>/2017/11/21/pass-multiple-functions-and-arguments-to-purrr-map/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/pass-multiple-functions-and-arguments-to-purrr-map/</guid>
      <description>I just run in the following problem: I wanted to map multiple functions to multiple columns, and I needed to pass some arguments to this map call. Sound theoretical, I know. Consider this example:
library(tidyverse) ## ── Attaching packages ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.5 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.</description>
    </item>
    
    <item>
      <title>Great dataviz examples in rstats</title>
      <link>/2017/11/20/great-dataviz-examples-in-rstats/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/20/great-dataviz-examples-in-rstats/</guid>
      <description>Here come some stunning examples of data visualizations, all built with R. R code of each diagram is available at the source. Enjoy! #beautiful.
UPDATE: I&amp;rsquo;ve included links to the R source!
Plotting geo maps along with subplots in ggplot2 I like this one by Ilya Kashnitsky:
Similarly, by the same author:
Source
Great work, @ikashnitsky!
Cirlize (Chord) diagrams Plotting association in a circular form yields aesthetic examples of diagrams, see the following examples</description>
    </item>
    
    <item>
      <title>Mapping foreigner ratio to AfD election results in the German Wahlkreise</title>
      <link>/2017/10/22/mapping-foreigner-ratio-to-afd-election-results-in-the-german-wahlkreise/</link>
      <pubDate>Sun, 22 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/22/mapping-foreigner-ratio-to-afd-election-results-in-the-german-wahlkreise/</guid>
      <description>In a previous post, we have shed some light on the idea that populism - as manifested in AfD election results - is associated with socioeconomic deprivation, be it subjective or objective. We found some supporting pattern in the data, although that hypothesis is far from being complete; ie., most of the variance remained unexplained.
In this post, we test the hypothesis that AfD election results are negatively associated with the proportion of foreign nationals in a Wahlkreis.</description>
    </item>
    
    <item>
      <title>Crashkurs Datenanalyse mit R</title>
      <link>/2017/05/16/crashkurs/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/16/crashkurs/</guid>
      <description>Nicht jeder liebt Datenanalyse und Statistik… in gleichem Maße. Das ist zumindest meine Erfahrung aus dem Unterricht :neckbeard: :fire:. Crashkurse zu R sind vergleichbar zu Crahskursen zu Französisch - kann man machen, aber es sollte die Maxime gelten “If everything else fails”.
Dieser Crashkurs ist für Studierende oder Anfänger der Datenanalyse gedacht, die in kurzer Zeit einen verzweifelten Versuch … äh … einen grundständigen Überblick über die Datenanalyse erwerben wollen.</description>
    </item>
    
    <item>
      <title>Deriving the logits for logistic regression</title>
      <link>/2017/05/06/deriving-the-logits-for-logistic-regression/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/06/deriving-the-logits-for-logistic-regression/</guid>
      <description>The logistic regression is an incredible useful tool, partly because binary outcomes are so frequent in live (“she loves me - she doesn’t love me”). In parts because we can make use of well-known “normal” regression instruments.
But the formula of logistic regression appears opaque to many (beginners or those with not so much math background).
Let’s try to shed some light on the formula by discussing some accessible explanation on how to derive the formula.</description>
    </item>
    
  </channel>
</rss>