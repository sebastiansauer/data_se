<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rstats on Data Se</title>
    <link>/categories/rstats/</link>
    <description>Recent content in Rstats on Data Se</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/rstats/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Visualisation of interaction for the logistic regression</title>
      <link>/2018/04/02/visualisation-of-interaction-for-logistic-regression/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/02/visualisation-of-interaction-for-logistic-regression/</guid>
      <description>In this post we are plotting an interaction for a logistic regression. Interaction per se is a concept difficult to grasp; for a GLM it may be even more difficult especially for continuous variables‚Äô interaction. Plotting helps to better or more easy grasp what a model tries to tell us.
First, load some packages.
 library(tidyverse) library(titanic) library(broom) library(modelr) library(knitr) We will deal with the well-known Titanic data, ie., we check which predictors augment survival probability:</description>
    </item>
    
    <item>
      <title>How to cite in markdown, a short primer</title>
      <link>/2018/03/26/how-to-cite-in-markdown-a-short-primer/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/26/how-to-cite-in-markdown-a-short-primer/</guid>
      <description>I would never write a paper again using Word - except I would be forced, too, what will happen, I think. But similarly, I don‚Äôt want to write papers using Latex - too many curly braces.
Best of both worlds: Markdown. Comes with ‚Äúbuiltin‚Äù R.
Here‚Äôs an example how to do scholarly citation in markdown.
In-Text citation Use this notation, to cite some book or paper or whatever:
The Good, the Bad, and the Ugly face similarly difficulties [@thedude2012].</description>
    </item>
    
    <item>
      <title>Why &#34;n-1&#34; in empirical variance? A simulation.</title>
      <link>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</guid>
      <description>It is well-known that the empirical variance underestimates the population variance. Specifically, the empirical variance is defined as: \(var_{emp} = \frac{\sum_i (x_i - \bar{x})^2}{n-1}\). But why \(n-1\), why not just \(n\), as intuition (of some) dictates? Put shortly, as the variance of a sample tends to underestimate the population variance we have to inflate it artificially, to enlarge it, that‚Äôs why we do put a smaller number (the ‚Äún-1‚Äù) in the denominator, resulting in a larger value of the whole fraction.</description>
    </item>
    
    <item>
      <title>Tangible data of normal distributed data</title>
      <link>/2018/03/16/tangible-data-of-normal-distributed-data/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/16/tangible-data-of-normal-distributed-data/</guid>
      <description>A classical example for a normally distributed variable is height. However, I kept on looking for data as to the mean and sd for some populations, such as Germany. Now I found some reliably looking data here.
We will not question whether the assumption of normality holds, we just assume it.
In the source, we can read that in Germany, the adult men population has the following parameters:
mean: 174cm</description>
    </item>
    
    <item>
      <title>Map students to presentation slots</title>
      <link>/2018/03/11/map-students-to-presentation-slots/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/11/map-students-to-presentation-slots/</guid>
      <description>As a teacher, I not only teach but also assess the achievements of students. One example of a typical student assignments is a presentation. You know, powerpoint slides and stuff.
For that purpose, I often need to map students to one of several time slots. Here‚Äôs the R code I use for that purpose.
library(tidyverse) How many students are subscribed to the assignment?
stud_count &amp;lt;- 20 Let‚Äôs say there 20 students in the course.</description>
    </item>
    
    <item>
      <title>Intuition to Simpson&#39;s paradox</title>
      <link>/2018/03/09/intuition-to-simpson-s-paradox/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/09/intuition-to-simpson-s-paradox/</guid>
      <description>Say, you have to choose between two doctors (Anna and Berta). To decide which one is better, you check their success rates. Suppose that they deal with two conditions (Coolities and Dummities). So let‚Äôs compare their success rate for each of the two conditions (and the total success rate):
This is the proportion of healing (success) of the first doctor, Dr. Anna for each of the two conditions:
 Coolities: 7 out of 8 patients are healed from Coolities Dummieties: 1 out of 2 patients are healed from Dummities  This is the proportion of healing (success) of the first doctor, Dr.</description>
    </item>
    
    <item>
      <title>How to create columns in a dataframe in R</title>
      <link>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</guid>
      <description>Note that we will use this library for this post:
library(dplyr) By the way, loading mosaic, will load dplyr too.
One of the major data wrangling activities (in R and elsewhere) is to create a new column in a data frame. For example, assume you have some students who have completed some exercises. In each row of the dataframe - one student. In each column - one exercise (called item). The dataframe might then look like this:</description>
    </item>
    
    <item>
      <title>Simulate p-hacking - adding observations</title>
      <link>/2018/01/24/simulate-p-hacking-adding-observations/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/24/simulate-p-hacking-adding-observations/</guid>
      <description>Let‚Äôs simulate p-values as a funtion of sample size. We assume that some researcher collects one data point, computes the p-value, and repeats until p-value falls below some arbitrary threshold. Oh and yes, there is no real effect. For the sake of spending the budget, assume that our researcher collects a sample size of \(n=100\).
This idea stems from this great article False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant; cf.</description>
    </item>
    
    <item>
      <title>Visualizing a logistic regression the easy way</title>
      <link>/2018/01/23/visualizing-a-logistic-regression-the-easy-way/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/23/visualizing-a-logistic-regression-the-easy-way/</guid>
      <description>Let‚Äôs visualize a GLM (logistic regression).
First laod some data:
data(tips, package = &amp;quot;reshape2&amp;quot;) Compute a glm:
glm_tips &amp;lt;- glm(sex ~ tip, data = tips, family = &amp;quot;binomial&amp;quot;) Plot the model using mosaic:
library(mosaic) plotModel(glm_tips) The curve does not look really s-typed (ogive) but that‚Äôs ok because the data suggest not a strong trend. The plot is not very beautiful either, but hey - it‚Äôs quick to produce üòÅ.</description>
    </item>
    
    <item>
      <title>Zusammenhang von Lernen und Noten im Statistikunterricht</title>
      <link>/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</guid>
      <description>F√ºhrt Lernen zu besseren Noten? Eigene Erfahrung und allgemeiner Konsens stimmen dem zu; zumindest schadet Lernen des Stoffes nicht und hilft oft, gute Noten bei einer Pr√ºfung zu diesem Stoff zu erzielen. Aber welche Belege, wissenschaftliche Belege gibt es dazu? An unserer Hochschule, die FOM, haben wir eine kleine Untersuchung zu dieser Frage durchgef√ºhrt. Genauer gesagt haben wir unseren Studierenden einen Statistik-Test vorlegt und gefagt, wie sehr sie sich f√ºr diesen Test vorbereitet h√§tten.</description>
    </item>
    
    <item>
      <title>A p-value picture</title>
      <link>/2017/11/29/a-p-value-picture/</link>
      <pubDate>Wed, 29 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/29/a-p-value-picture/</guid>
      <description>Much ado and to say about the p-value. Let me add one more point; actually not really from myself, but from Diez, Barr, and Cetinkaya-Rundel (2012), p.¬†189; good book in one is looking for ‚Äúorthodox‚Äù statistics.
library(tidyverse) ggplot(NULL, aes(c(-5,5))) + geom_area(stat = &amp;quot;function&amp;quot;, fun = dnorm, fill = &amp;quot;grey40&amp;quot;, xlim = c(-5, 2)) + geom_area(stat = &amp;quot;function&amp;quot;, fun = dnorm, fill = &amp;quot;#00998a&amp;quot;, xlim = c(2, 5)) + labs(y = &amp;quot;&amp;quot;, x = &amp;quot;X&amp;quot;) + theme(axis.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R</title>
      <link>/2017/11/28/textmining-grundlagen/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/28/textmining-grundlagen/</guid>
      <description>Lernziele:
  - Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &amp;#39;tidy text dataframe&amp;#39; ist. - Sie k√∂nnen Worth√§ufigkeiten ausz√§hlen. - Sie k√∂nnen Worth√§ufigkeiten anhand einer Wordcloud visualisieren. In dieser √úbung ben√∂tigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopw√∂rter library(SnowballC) # W√∂rter trunkieren library(wordcloud) # Wordcloud anzeigen  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio √ºber den Reiter Packages ‚Ä¶ Install.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R - Teil 2</title>
      <link>/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</guid>
      <description>In dieser √úbung ben√∂tigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopw√∂rter library(SnowballC) # W√∂rter trunkieren library(wordcloud) # Wordcloud anzeigen library(skimr) # √úberblicksstatistiken  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio √ºber den Reiter Packages ‚Ä¶ Install.
 Aus dem letzten Post Daten einlesen:
osf_link &amp;lt;- paste0(&amp;quot;https://osf.io/b35r7//?action=download&amp;quot;) afd &amp;lt;- read_csv(osf_link) Aus breit mach lang:
afd %&amp;gt;% unnest_tokens(output = token, input = content) %&amp;gt;% dplyr::filter(str_detect(token, &amp;quot;[a-z]&amp;quot;)) -&amp;gt; afd_long Stopw√∂rter entfernen:</description>
    </item>
    
    <item>
      <title>Dummy variables and regression</title>
      <link>/2017/11/27/dummy-variables-and-regression/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/dummy-variables-and-regression/</guid>
      <description>For modeling cause-effect relationships, linear regression is among the most typically used methods.
Take, for example, the idea that the Gross Domestic Product (GDP) drives religiosity. Of course, we should have a strong theory that defends this choice and this directionality. Without a convincing theory it may be argued that the cause-relationship is the other way round or complete different (ie., some third variable accounts for any association between GDP and religiosity).</description>
    </item>
    
    <item>
      <title>Interactive diagrams in lieu of shiny?</title>
      <link>/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</guid>
      <description>One frequent use of the Shiny server software is displaying interactive data diagrams. The pro of using Shiny is the great flexibility; much more than ‚Äújust graphics‚Äù can be done.</description>
    </item>
    
    <item>
      <title>My favorite stats text book</title>
      <link>/2017/11/27/my-favorite-stats-text-book/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/27/my-favorite-stats-text-book/</guid>
      <description>Some thoughts how my favorite applied stats text book would look like. I am looking at eg., business fields such as MBA as consumers.
My ideal applied stats text book is case study oriented (‚ÄúAssume you would like to predict which movie will score highest next year based on some movie characteristics you know‚Äù)
 makes use of recent data analytics techniques such as tree based methods (Random Forests) or Shrinkage models (Lasso)</description>
    </item>
    
    <item>
      <title>Use case for purrr::map</title>
      <link>/2017/11/23/use-case-for-purrr-map/</link>
      <pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/23/use-case-for-purrr-map/</guid>
      <description>library(tidyverse) d &amp;lt;- data_frame( id = c(1,1,1,1,1,1,2,2,3,3,3,4,1,2,2) ) d$id %&amp;gt;% map </description>
    </item>
    
    <item>
      <title>Compute effect sizes with R. A primer.</title>
      <link>/2017/11/21/compute-effect-sizes-with-r-a-primer/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/compute-effect-sizes-with-r-a-primer/</guid>
      <description>A typical ‚Äúcook book recipe‚Äù for doing data analysis is an applied stats course is:
report descriptive statistics plot some nice diagrams test hypothesis report effect sizes  Let‚Äôs have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &amp;quot;nycflights13&amp;quot;) This post will be tidyverse-driven.
library(tidyverse) library(skimr) library(mosaic) Let‚Äôs compute some summaries:
flights %&amp;gt;% select(arr_delay) %&amp;gt;% skim #&amp;gt; Skim summary statistics #&amp;gt; n obs: 336776 #&amp;gt; n variables: 1 #&amp;gt; #&amp;gt; Variable type: numeric #&amp;gt; variable missing complete n mean sd p0 p25 median p75 p100 #&amp;gt; arr_delay 9430 327346 336776 6.</description>
    </item>
    
    <item>
      <title>Get your stats result in a table easily</title>
      <link>/2017/11/21/get-your-stats-result-in-a-table-easily/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/get-your-stats-result-in-a-table-easily/</guid>
      <description>Having computed some staticis, one would like to display them. Either in a figure, on in a table, that‚Äôs the two typical ways.
Let‚Äôs explore some helper functions to get your stats to a table easily.
A nice overview on packages can be found here.
Let‚Äôs have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &amp;quot;nycflights13&amp;quot;) This post will be tidyverse-driven:</description>
    </item>
    
    <item>
      <title>Pass multiple functions and arguments to purrr::map</title>
      <link>/2017/11/21/pass-multiple-functions-and-arguments-to-purrr-map/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/21/pass-multiple-functions-and-arguments-to-purrr-map/</guid>
      <description>I just run in the following problem: I wanted to map multiple functions to multiple columns, and I needed to pass some arguments to this map call. Sound theoretical, I know. Consider this example:
library(tidyverse) Build a vector of functions:
funs &amp;lt;- purrr::compose(median, mean, sd, IQR) And apply this composed function to each column of a dataframe:
mtcars[1:2]%&amp;gt;% map(funs, na.rm = TRUE) #&amp;gt; $mpg #&amp;gt; [1] NA #&amp;gt; #&amp;gt; $cyl #&amp;gt; [1] NA mtcars %&amp;gt;% map(funs, na.</description>
    </item>
    
    <item>
      <title>Great dataviz examples in rstats</title>
      <link>/2017/11/20/great-dataviz-examples-in-rstats/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/20/great-dataviz-examples-in-rstats/</guid>
      <description>Here come some stunning examples of data visualizations, all built with R. R code of each diagram is available at the source. Enjoy! #beautiful.
UPDATE: I&amp;rsquo;ve included links to the R source!
Plotting geo maps along with subplots in ggplot2 I like this one by Ilya Kashnitsky:
Similarly, by the same author:
Source
Great work, @ikashnitsky!
Cirlize (Chord) diagrams Plotting association in a circular form yields aesthetic examples of diagrams, see the following examples</description>
    </item>
    
    <item>
      <title>Deriving the logits for logistic regression</title>
      <link>/2017/05/06/deriving-the-logits-for-logistic-regression/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/06/deriving-the-logits-for-logistic-regression/</guid>
      <description>The logistic regression is an incredible useful tool, partly because binary outcomes are so frequent in live (‚Äúshe loves me - she doesn‚Äôt love me‚Äù). In parts because we can make use of well-known ‚Äúnormal‚Äù regression instruments.
But the formula of logistic regression appears opaque to many (beginners or those with not so much math background).
Let‚Äôs try to shed some light on the formula by discussing some accessible explanation on how to derive the formula.</description>
    </item>
    
  </channel>
</rss>