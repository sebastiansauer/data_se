<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.75.1" />


<title>Simulation based inference for non-parametric tests, and a trick - Data Se</title>
<meta property="og:title" content="Simulation based inference for non-parametric tests, and a trick - Data Se">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo-data-se.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/">Blog</a></li>
    
    <li><a href="/privacy/">Data privacy</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">6 min read</span>
    

    <h1 class="article-title">Simulation based inference for non-parametric tests, and a trick</h1>

    
    <span class="article-date">2020/06/05</span>
    

    <div class="article-content">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="load-packages" class="section level1">
<h1>Load packages</h1>
<pre class="r"><code>library(tidyverse)
library(mosaic)</code></pre>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<pre class="r"><code>data(&quot;tips&quot;, package = &quot;reshape2&quot;)</code></pre>
</div>
<div id="non-parametric-tests-and-simulation-based-inference" class="section level1">
<h1>Non-parametric tests and simulation based inference</h1>
<p>Simulation-based inference (SBI) is an old tool that has seen a surge in research interest in recent years probably due to the large amount of computational powers at the hands of researchers.</p>
<p>SBI is less prone to violations of assumptions, particularly with distributional assumptions. This is because inference is not based on the idea that some variable follows a – for example – normal distribution.</p>
<p>As a consequence there is much less need to seek shelter at nonparametric tests in case distributional assumptions are violated.</p>
<p>In this post, I’ll show how the Kurskal-Wallis test can be applied using SBI and how to translate it to a linear model.</p>
</div>
<div id="research-question" class="section level1">
<h1>Research question</h1>
<p>Is there a difference in mean tip across different days?</p>
</div>
<div id="kruskall-test-the-classic-way" class="section level1">
<h1>Kruskall test the classic way</h1>
<pre class="r"><code>k_test &lt;- kruskal.test(tip ~ day, data = tips)
k_test
#&gt; 
#&gt;  Kruskal-Wallis rank sum test
#&gt; 
#&gt; data:  tip by day
#&gt; Kruskal-Wallis chi-squared = 8.5656, df = 3, p-value = 0.03566</code></pre>
<p>Let’s have a closer look to the resulting object:</p>
<pre class="r"><code>str(k_test)
#&gt; List of 5
#&gt;  $ statistic: Named num 8.57
#&gt;   ..- attr(*, &quot;names&quot;)= chr &quot;Kruskal-Wallis chi-squared&quot;
#&gt;  $ parameter: Named int 3
#&gt;   ..- attr(*, &quot;names&quot;)= chr &quot;df&quot;
#&gt;  $ p.value  : num 0.0357
#&gt;  $ method   : chr &quot;Kruskal-Wallis rank sum test&quot;
#&gt;  $ data.name: chr &quot;tip by day&quot;
#&gt;  - attr(*, &quot;class&quot;)= chr &quot;htest&quot;</code></pre>
<p>We can extract the statistic in this way:</p>
<pre class="r"><code>k_test$statistic
#&gt; Kruskal-Wallis chi-squared 
#&gt;                   8.565588
pluck(k_test, &quot;statistic&quot;)
#&gt; Kruskal-Wallis chi-squared 
#&gt;                   8.565588</code></pre>
<p>Or, alternatively:</p>
<pre class="r"><code>kruskal.test(tip ~ day, data = tips)$statistic
#&gt; Kruskal-Wallis chi-squared 
#&gt;                   8.565588</code></pre>
<p>The statistic is defined as shown <a href="https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance">here</a>:</p>
<p><span class="math display">\[
H = (N-1)\frac{\sum_{i=1}^g n_i(\bar{r}_{i\cdot} - \bar{r})^2}{\sum_{i=1}^g\sum_{j=1}^{n_i}(r_{ij} - \bar{r})^2}
\]</span></p>
<p>And this statistic is asymptotically <span class="math inline">\(\chi^2\)</span> distributed.</p>
</div>
<div id="kruskall-test-via-sbi" class="section level1">
<h1>Kruskall test via SBI</h1>
<pre class="r"><code>null1 &lt;- do(1000) * kruskal.test(tip ~ shuffle(day), 
                                 data = tips)</code></pre>
<p>Let’s check the results:</p>
<pre class="r"><code>null1 %&gt;% 
  head() %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">Kruskal.Wallis.chi.squared</th>
<th align="right">df</th>
<th align="right">p.value</th>
<th align="left">method</th>
<th align="left">alternative</th>
<th align="left">data</th>
<th align="right">.row</th>
<th align="right">.index</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">7.0528110</td>
<td align="right">3</td>
<td align="right">0.0702334</td>
<td align="left">Kruskal-Wallis rank sum test</td>
<td align="left">NA</td>
<td align="left">tip by shuffle(day)</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">4.7100088</td>
<td align="right">3</td>
<td align="right">0.1943056</td>
<td align="left">Kruskal-Wallis rank sum test</td>
<td align="left">NA</td>
<td align="left">tip by shuffle(day)</td>
<td align="right">1</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td align="right">1.7082816</td>
<td align="right">3</td>
<td align="right">0.6350942</td>
<td align="left">Kruskal-Wallis rank sum test</td>
<td align="left">NA</td>
<td align="left">tip by shuffle(day)</td>
<td align="right">1</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">1.6742686</td>
<td align="right">3</td>
<td align="right">0.6426696</td>
<td align="left">Kruskal-Wallis rank sum test</td>
<td align="left">NA</td>
<td align="left">tip by shuffle(day)</td>
<td align="right">1</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">2.3733175</td>
<td align="right">3</td>
<td align="right">0.4986209</td>
<td align="left">Kruskal-Wallis rank sum test</td>
<td align="left">NA</td>
<td align="left">tip by shuffle(day)</td>
<td align="right">1</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="right">0.5323401</td>
<td align="right">3</td>
<td align="right">0.9117311</td>
<td align="left">Kruskal-Wallis rank sum test</td>
<td align="left">NA</td>
<td align="left">tip by shuffle(day)</td>
<td align="right">1</td>
<td align="right">6</td>
</tr>
</tbody>
</table>
</div>
<div id="plot-it" class="section level1">
<h1>Plot it</h1>
<p>Let’s add the empirical value as a vertical line.</p>
<pre class="r"><code>gf_histogram( ~ Kruskal.Wallis.chi.squared, data = null1) %&gt;% 
  gf_vline(xintercept = ~ k_test$statistic)</code></pre>
<p><img src="/post/2020-06-05-_files/figure-html/unnamed-chunk-8-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Let’s color the top-5 percent red, to highlight the critical value.</p>
<pre class="r"><code>null1 &lt;- null1 %&gt;% 
  mutate(is_top5percent = percent_rank(Kruskal.Wallis.chi.squared)  &gt; .95)</code></pre>
<pre class="r"><code>gf_histogram( ~ Kruskal.Wallis.chi.squared, 
              data = null1,
              fill = ~ is_top5percent) %&gt;% 
  gf_vline(xintercept = ~ k_test$statistic)</code></pre>
<p><img src="/post/2020-06-05-_files/figure-html/unnamed-chunk-10-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="nice-but" class="section level1">
<h1>Nice, but …</h1>
<p>As outlined above, there may be no need to bypass the test of the mean. Using SBI one does not have to assume normal distribution of the variable tested if one would like to compute p-values.</p>
</div>
<div id="linear-model-for-comparing-means" class="section level1">
<h1>Linear model for comparing means</h1>
<pre class="r"><code>lm1 &lt;- lm(tip ~ day, data = tips)
lm1_sum &lt;- summary(lm1)

lm1_sum
#&gt; 
#&gt; Call:
#&gt; lm(formula = tip ~ day, data = tips)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -2.2451 -0.9931 -0.2347  0.5382  7.0069 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)  2.73474    0.31612   8.651 7.46e-16 ***
#&gt; daySat       0.25837    0.34893   0.740    0.460    
#&gt; daySun       0.52039    0.35343   1.472    0.142    
#&gt; dayThur      0.03671    0.36132   0.102    0.919    
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 1.378 on 240 degrees of freedom
#&gt; Multiple R-squared:  0.02048,    Adjusted R-squared:  0.008232 
#&gt; F-statistic: 1.672 on 3 and 240 DF,  p-value: 0.1736</code></pre>
<p>As can be seen, the <span class="math inline">\(F\)</span> value is not significant thereby questioning the difference in means hypothesis. Put differently: The models sees no strong evidence for rejecting the null.</p>
<p>The F value, along with its 3 df values, can be plucked out like this:</p>
<pre class="r"><code>emp_F_value &lt;- pluck(lm1_sum, &quot;fstatistic&quot;)
emp_F_value
#&gt;      value      numdf      dendf 
#&gt;   1.672355   3.000000 240.000000</code></pre>
<p>Note that this is a vector of three 3 elements.</p>
</div>
<div id="linear-model-using-sbi" class="section level1">
<h1>Linear model using SBI</h1>
<p>Now the trick.</p>
<pre class="r"><code>boot1 &lt;- do(1000) * lm(tip ~ day, data = resample(tips))

confint(boot1)
#&gt;        name        lower      upper level     method   estimate
#&gt; 1 Intercept  2.244986111 3.16854386  0.95 percentile 2.73473684
#&gt; 2    daySat -0.277850907 0.87533265  0.95 percentile 0.25836661
#&gt; 3    daySun  0.024210182 1.07589364  0.95 percentile 0.52039474
#&gt; 4   dayThur -0.503510671 0.60336794  0.95 percentile 0.03671477
#&gt; 5     sigma  1.159307959 1.58166629  0.95 percentile 1.37793112
#&gt; 6 r.squared  0.004987298 0.07738975  0.95 percentile 0.02047639
#&gt; 7         F  0.400983682 6.71050426  0.95 percentile 1.67235520</code></pre>
</div>
<div id="pluck-the-r-squared-from-the-lm-object" class="section level1">
<h1>Pluck the r-squared from the lm object</h1>
<p>Here’s a way to pluck the R squared value from the lm object:</p>
<pre class="r"><code>lm(tip ~ day, data = tips) %&gt;% 
  summary() %&gt;% 
  pluck(&quot;r.squared&quot;)
#&gt; [1] 0.02047639</code></pre>
</div>
<div id="plot-the-results" class="section level1">
<h1>Plot the results</h1>
<pre class="r"><code>gf_histogram(~ r.squared, data = boot1) %&gt;% 
  gf_vline( xintercept = ~ lm(tip ~ day, data = tips) %&gt;% 
              summary() %&gt;% 
              pluck(&quot;r.squared&quot;))</code></pre>
<p><img src="/post/2020-06-05-_files/figure-html/unnamed-chunk-15-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Interestingly, the R squeared distribution is not normally distributed. In sum, the R squared are really small.</p>
</div>
<div id="test-the-null-using-lm-and-sbi" class="section level1">
<h1>Test the null using lm and SBI</h1>
<pre class="r"><code>null2 &lt;- do(1000) * lm(tip ~ shuffle(day), data = tips)</code></pre>
<p>Let’s check the <span class="math inline">\(F\)</span> statistic. The critical value of the <span class="math inline">\(F\)</span> statistic is, given 3 and 240 degrees of freedom (as shown by the lm output):</p>
<pre class="r"><code>crit_f &lt;- qf(p = 0.95, 
             df1 = 3,
             df2 = 240)
crit_f
#&gt; [1] 2.642213</code></pre>
<p>Plot it:</p>
<pre class="r"><code>null2 &lt;- null2 %&gt;% 
  mutate(top_5percent = percent_rank(F) &gt; 0.95)

gf_histogram(~ F, data = null2,
             fill =~top_5percent) %&gt;% 
  gf_vline(xintercept = ~emp_F_value[1]) %&gt;% 
  gf_label(label = ~ paste0(&quot;F: &quot;,
                            emp_F_value[1] %&gt;% round(2)),  
           x = ~ emp_F_value[1], 
           y = 0,
           show.legend = FALSE) </code></pre>
<p><img src="/post/2020-06-05-_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>As can be seen, the F value is not significant.</p>
<p>Some summary statistics to this distribution:</p>
<pre class="r"><code>favstats(~ F, data = null2)
#&gt;        min        Q1    median       Q3      max      mean        sd    n
#&gt;  0.0092523 0.4050921 0.7621598 1.356379 5.611243 0.9925849 0.8319289 1000
#&gt;  missing
#&gt;        0</code></pre>
</div>
<div id="caution" class="section level1">
<h1>Caution</h1>
<p>Note that the <a href="https://amstat.tandfonline.com/doi/full/10.1080/00031305.2016.1154108">ASA</a> advises that the p-value should not be the (sole) basis of decision in any data analysis.</p>
<p>Bayesian statistics is a neat alternative.</p>
</div>
<div id="anova" class="section level1">
<h1>ANOVA</h1>
<p>As can be seen, the Kruskal Wallis and the F tests yield different results. This is probably due to the fact that we tested median differences (Kruskall) and later on mean differences (F test).</p>
<p>As a check, here’s a standard ANOVA:</p>
<pre class="r"><code>aov1 &lt;- aov(tip ~ day, data = tips)
summary(aov1)
#&gt;              Df Sum Sq Mean Sq F value Pr(&gt;F)
#&gt; day           3    9.5   3.175   1.672  0.174
#&gt; Residuals   240  455.7   1.899</code></pre>
<p>Replicating the F value decision from the SBI analysis above.</p>
</div>
<div id="plotting-medians-vs-means" class="section level1">
<h1>Plotting medians vs means</h1>
<p>As a further check, let’s plot median and mean differences for the sake of comparison.</p>
<pre class="r"><code>gf_point(tip ~ day, 
         data = tips,
         stat = &quot;summary&quot;, 
         fun = mean,
         shape = 3,
         size = 5,
         color = &quot;blue&quot;) +
  stat_summary(geom = &quot;point&quot;, 
               fun = median,
               color = &quot;red&quot;,
               size = 5,
               shape = 5) +
  labs(caption = &quot;Crosses: Mean, diamonds: Median&quot;)</code></pre>
<p><img src="/post/2020-06-05-_files/figure-html/unnamed-chunk-21-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>As ca be seen, the median values are more spread out, hence it appears sensible that the test would get significant whereas the more clustered mean values do not show a significant difference in our test.</p>
</div>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-data-se-netlify-com.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

