

  
    
  


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.21 with theme Tranquilpeak 0.4.3-BETA">
    <title>Grundlagen des Textminings mit R</title>
    <meta name="author" content="Sebastian Sauer">
    <meta name="keywords" content=", rstats, datascience">

    <link rel="icon" href="/favicon.png">
    

    
    <meta name="description" content="Lernziele:
  - Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &#39;tidy text dataframe&#39; ist. - Sie können Worthäufigkeiten auszählen. - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren. In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.">
    <meta property="og:description" content="Lernziele:
  - Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &#39;tidy text dataframe&#39; ist. - Sie können Worthäufigkeiten auszählen. - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren. In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Grundlagen des Textminings mit R">
    <meta property="og:url" content="/2017/11/textmining-grundlagen/">
    <meta property="og:site_name" content="Data Se">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Data Se">
    <meta name="twitter:description" content="Lernziele:
  - Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &#39;tidy text dataframe&#39; ist. - Sie können Worthäufigkeiten auszählen. - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren. In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.">
    
      <meta name="twitter:creator" content="@sauer_sebastian">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/8851f7754d1792f008b8874cd258f5b7?s=640">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-99297878-1', 'auto');
ga('send', 'pageview');
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">Data Se</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/8851f7754d1792f008b8874cd258f5b7?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/8851f7754d1792f008b8874cd258f5b7?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Sebastian Sauer</h4>
        
          <h5 class="sidebar-profile-bio"><strong>Data Scie</strong>nce blog of Sebastian Sauer</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/sebastiansauer">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Grundlagen des Textminings mit R
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2017-11-28T00:00:00Z">
        
  November 28, 2017

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/rstats">rstats</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <blockquote>
<p>Lernziele:</p>
</blockquote>
<pre><code>  - Sie kennen zentrale Ziele und Begriffe des Textminings.
  - Sie wissen, was ein &#39;tidy text dataframe&#39; ist.
  - Sie können Worthäufigkeiten auszählen.
  - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren.</code></pre>
<p>In dieser Übung benötigte R-Pakete:</p>
<pre class="r"><code>library(tidyverse)  # Datenjudo
library(stringr)  # Textverarbeitung
library(tidytext)  # Textmining
library(lsa)  # Stopwörter 
library(SnowballC)  # Wörter trunkieren
library(wordcloud)  # Wordcloud anzeigen</code></pre>
<blockquote>
<p>Bitte installieren Sie <em>rechtzeitig</em> alle Pakete, z.B. in RStudio über den Reiter <em>Packages … Install</em>.</p>
</blockquote>
<p>Ein großer Teil der zur Verfügung stehenden Daten liegt nicht als braves Zahlenmaterial vor, sondern in “unstrukturierter” Form, z.B. in Form von Texten. Im Gegensatz zur Analyse von numerischen Daten ist die Analyse von Texten weniger verbreitet bisher. In Anbetracht der Menge und der Informationsreichhaltigkeit von Text erscheint die Analyse von Text als vielversprechend.</p>
<p>In gewisser Weise ist das Textmining ein alternative zu klassischen qualitativen Verfahren der Sozialforschung. Geht es in der qualitativen Sozialforschung primär um das Verstehen eines Textes, so kann man für das Textmining ähnliche Ziele formulieren. Allerdings: Das Textmining ist wesentlich schwächer und beschränkter in der Tiefe des Verstehens. Der Computer ist einfach noch (?) wesentlich <em>dümmer</em> als ein Mensch, zumindest in dieser Hinsicht. Allerdings ist er auch wesentlich <em>schneller</em> als ein Mensch, was das Lesen betrifft. Daher bietet sich das Textmining für das Lesen großer Textmengen an, in denen eine geringe Informationsdichte vermutet wird. Sozusagen maschinelles Sieben im großen Stil. Da fällt viel durch die Maschen, aber es werden Tonnen von Sand bewegt.</p>
<p>In der Regel wird das Textmining als <em>gemischte</em> Methode verwendet: sowohl qualitative als auch qualitative Aspekte spielen eine Rolle. Damit vermittelt das Textmining auf konstruktive Art und Weise zwischen den manchmal antagonierenden Schulen der qualitativ-idiographischen und der quantitativ-nomothetischen Sichtweise auf die Welt. Man könnte es auch als qualitative Forschung mit moderner Technik bezeichnen - mit den skizzierten Einschränkungen wohlgemerkt.</p>
<div id="zentrale-begriffe" class="section level2">
<h2>Zentrale Begriffe</h2>
<p>Die computergestützte Analyse von Texten speiste (und speist) sich reichhaltig aus Quellen der Linguistik; entsprechende Fachtermini finden Verwendung:</p>
<ul>
<li><p>Ein <em>Corpus</em> bezeichnet die Menge der zu analysierenden Dokumente; das könnten z.B. alle Reden der Bundeskanzlerin Angela Merkel sein oder alle Tweets von “@realDonaldTrump”.</p></li>
<li><p>Ein <em>Token</em> (<em>Term</em>) ist ein elementarer Baustein eines Texts, die kleinste Analyseeinheit, häufig ein Wort.</p></li>
<li><p>Unter <em>tidy text</em> versteht man einen Dataframe, in dem pro Zeile nur <em>ein</em> Token (z.B. Wort) steht. Synonym könnte man von einem “langen” Dataframe sprechen.</p></li>
</ul>
</div>
<div id="grundlegende-analyse" class="section level2">
<h2>Grundlegende Analyse</h2>
<div id="tidy-text-dataframes" class="section level3">
<h3>Tidy Text Dataframes</h3>
<p>Wozu ist es nützlich, einen Text-Dataframe in einen langen Dataframe umzuwandeln? Der Grund ist, dass immer wenn nur ein Wort (allgemeiner: Term) pro Zelle steht, dann können wir die Spalte einfach auszählen. Wir können z.B. <code>count</code> nutzen, um zu zählen, wie häufig ein Wort vorkommt. Sprich: Sobald wir einen langen (Text-)Dataframe haben, können wir unsere bekannte Methoden einsetzen.</p>
<p>Basteln wir uns einen <em>tidy text</em> Dataframe. Wir gehen dabei von einem Vektor mit mehreren Text-Elementen aus, das ist ein realistischer Startpunkt. Unser Text-Vektor<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> besteht aus 4 Elementen.</p>
<pre class="r"><code>text &lt;- c(&quot;Wir haben die Frauen zu Bett gebracht,&quot;,
          &quot;als die Männer in Frankreich standen.&quot;,
          &quot;Wir hatten uns das viel schöner gedacht.&quot;,
          &quot;Wir waren nur Konfirmanden.&quot;)</code></pre>
<p>Als nächstes machen wir daraus einen Dataframe.</p>
<pre class="r"><code>text_df &lt;- data_frame(Zeile = 1:4,
                      text = text)</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">Zeile</th>
<th align="left">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Wir haben die Frauen zu Bett gebracht,</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">als die Männer in Frankreich standen.</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="left">Wir hatten uns das viel schöner gedacht.</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="left">Wir waren nur Konfirmanden.</td>
</tr>
</tbody>
</table>
<p>Übrigens, falls Sie eine beliebige Textdatei einlesen möchten, können Sie das so tun:</p>
<pre class="r"><code>text &lt;- read_lines(&quot;Brecht.txt&quot;)</code></pre>
<p>Der Befehl <code>read_lines</code> (aus <code>readr</code><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>) liest Zeilen (Zeile für Zeile) aus einer Textdatei.</p>
<blockquote>
<p>Wenn Sie <em>keinen</em> Pfad angeben, dann geht R davon aus, dass sich die angegebene Datei im Arbeitsverzeichnis befindet. Welcher Ordner ist Ihr Arbeitsverzeichnis? Klicken Sie in RStudio auf <em>Session &gt; Set Working Directory…</em> um zu erfahren, welcher Ordner im Moment Ihr Arbeitsverzeichnis ist. Dort können Sie auch Ihr Arbeitsverzeichnis einstellen.</p>
</blockquote>
<p>Als nächstes “dehnen” wir den Dataframe zu einem <em>tidy text</em> Dataframe (s. Abb. <a href="#fig:tidytextdf">1</a>); das besorgt die Funktion <code>unnest_tokens</code> aus `tidytext. ‘unnest’ heißt dabei so viel wie ‘Entschachteln’, also von breit auf lang dehnen. Mit ‘tokens’ sind hier einfach die Wörter gemeint (es könnten aber auch andere Analyseeinheiten sein, Sätze zum Beispiel).</p>
<div class="figure" style="text-align: center"><span id="fig:tidytextdf"></span>
<img src="/images/textmining/tidytext-crop.png" alt="Illustration eines Tidy Text Dataframe" width="100%" />
<p class="caption">
Figure 1: Illustration eines Tidy Text Dataframe
</p>
</div>
<pre class="r"><code>text_df %&gt;% 
  unnest_tokens(output = wort, input = text) -&gt; tidytext_df

head(tidytext_df)
#&gt; # A tibble: 6 x 2
#&gt;   Zeile   wort
#&gt;   &lt;int&gt;  &lt;chr&gt;
#&gt; 1     1    wir
#&gt; 2     1  haben
#&gt; 3     1    die
#&gt; 4     1 frauen
#&gt; 5     1     zu
#&gt; 6     1   bett</code></pre>
<p>Der Parameter <code>output</code> sagt, wie neue ‘saubere’ (lange) Spalte heißen soll; <code>input</code> sagt der Funktion, welche Spalte sie als ihr Futter (Input) betrachten soll (welche Spalte in tidy text umgewandelt werden soll).</p>
<pre><code>Nehme den Datensatz &quot;text_df&quot; UND DANN  
dehne die einzelnen Elemente der Spalte &quot;text&quot;, so dass jedes Element seine eigene Spalte bekommt.  
Ach ja: Diese &quot;gedehnte&quot; Spalte soll &quot;wort&quot; heißen (weil nur einzelne Wörter drinnen stehen) UND DANN  
speichere den resultierenden Dataframe ab als `tidytext_df`.</code></pre>
<blockquote>
<p>In einem ‘tidy text Dataframe’ steht in jeder Zeile ein Wort (token) und die Häufigkeit des Worts im Dokument.</p>
</blockquote>
<p>Überprüfen Sie, ob das stimmt: Betrachten Sie den Dataframe <code>tidytext_df</code>.</p>
<p>Das <code>unnest_tokens</code> kann übersetzt werden als “entschachtele” oder “dehne” die Tokens - so dass in <em>jeder Zeile</em> nur noch <em>ein Wort</em> (genauer: Token) steht. Die Syntax ist <code>unnest_tokens(Ausgabespalte, Eingabespalte)</code>. Nebenbei werden übrigens alle Buchstaben auf Kleinschreibung getrimmt.</p>
<p>Als nächstes filtern wir die Satzzeichen heraus, da die Wörter für die Analyse wichtiger (oder zumindest einfacher) sind.</p>
<pre class="r"><code>tidytext_df %&gt;% 
  filter(str_detect(wort, &quot;[a-z]&quot;)) -&gt; tidytext_df_lowercase</code></pre>
<p>In Pseudo-Code heißt dieser Abschnitt:</p>
<pre><code>Nehme den Datensatz &quot;tidytext_df&quot; UND DANN  
filtere die Spalte &quot;wort&quot;, so dass nur noch Kleinbuchstaben übrig bleiben (keine Ziffern etc.). FERTIG.  </code></pre>
</div>
<div id="text-daten-einlesen" class="section level3">
<h3>Text-Daten einlesen</h3>
<div id="als-csv-datei-einlesen" class="section level4">
<h4>Als CSV-Datei einlesen</h4>
<p>Nun lesen wir Text-Daten ein; das können beliebige Daten sein<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. Eine gewisse Reichhaltigkeit im Text ist von Vorteil. Nehmen wir das Parteiprogramm der Partei AfD<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>. Vor dem Hintergrund des Erstarkens des Populismus weltweit und der großen Gefahr, die davon ausgeht - man blicke auf die Geschichte Europas in der ersten Hälfte des 20. Jahrhunderts - <del>verdient</del>erfordert der politische Prozess und speziell Neuentwicklungen darin unsere besondere Beachtung. Das Parteiprogramm kann hier als CSV-Datei von <a href="https://osf.io/b35r7/" class="uri">https://osf.io/b35r7/</a> eingelesen werden:</p>
<pre class="r"><code>osf_link &lt;- paste0(&quot;https://osf.io/b35r7//?action=download&quot;)
afd &lt;- read_csv(osf_link)</code></pre>
</div>
<div id="als-pdf-oder-unstrukturierte-text-datei-einlesen" class="section level4">
<h4>Als PDF oder unstrukturierte Text-Datei einlesen</h4>
<p>Häufig sind Textdateien in Textdateien gespeichert, dann kann man mit <code>readr::read_lines</code> Daten, die keine Tabellenstruktur haben einlesen. Ein anderes häufiges Format sind PDF-Dateien; dafür bietet das Paket <code>pdftools</code> die Funktion <code>pdf_text</code>, die den Inhalt einer PDF-Datei einliest. Jede Seite wird dabei als ein Element eines Vektors abgespeichert. Hätten wir die PDF-Datei vorliegen, so könnten wir sie mit <code>pdf_text</code> einlesen. Der resultierende Vektor <code>afd_raw</code> hat 96 Elemente (entsprechend der Seitenzahl des Dokuments). Wandeln wir als nächstes den Vektor in einen Dataframe um.</p>
<pre class="r"><code>afd_pfad &lt;- &quot;data/afd_programm.pdf&quot;
afd_raw &lt;- pdf_text(afd_pfad)
afd &lt;- data_frame(Zeile = 1:96, 
                  afd_raw)</code></pre>
</div>
<div id="daten-sind-da---jetzt-aufhubschen" class="section level4">
<h4>Daten sind da - jetzt aufhübschen</h4>
<p>Im Ergebnis hätten wir einen Dataframe, ein Prachtstück. Mit <code>head(afd)</code> können Sie sich den Beginn dieses Textvektor anzeigen lassen. Auch die Stopwörter entfernen wir wieder wie gehabt.</p>
<pre class="r"><code>afd %&gt;% 
  unnest_tokens(output = token, input = content) %&gt;% 
  dplyr::filter(str_detect(token, &quot;[a-z]&quot;)) -&gt; afd_long</code></pre>
<p>Insgesamt 26396 Wörter<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>; eine substanzielle Menge von Text. Was wohl die häufigsten Wörter sind?</p>
</div>
</div>
<div id="worthaufigkeiten-auszahlen" class="section level3">
<h3>Worthäufigkeiten auszählen</h3>
<pre class="r"><code>afd_long %&gt;% 
  na.omit() %&gt;%  # fehlende Werte löschen
  count(token, sort = TRUE)
#&gt; # A tibble: 7,087 x 2
#&gt;    token     n
#&gt;    &lt;chr&gt; &lt;int&gt;
#&gt;  1   die  1151
#&gt;  2   und  1147
#&gt;  3   der   870
#&gt;  4    zu   435
#&gt;  5   für   392
#&gt;  6    in   392
#&gt;  7   den   271
#&gt;  8   von   257
#&gt;  9   ist   251
#&gt; 10   das   225
#&gt; # ... with 7,077 more rows</code></pre>
<p>Die häufigsten Wörter sind inhaltsleere Partikel, Präpositionen, Artikel… Solche sogenannten “Stopwörter” sollten wir besser herausfischen, um zu den inhaltlich tragenden Wörtern zu kommen. Praktischerweise gibt es frei verfügbare Listen von Stopwörtern, z.B. im Paket <code>lsa</code>.</p>
<pre class="r"><code>data(stopwords_de, package = &quot;lsa&quot;)

stopwords_de &lt;- data_frame(word = stopwords_de)

# Für das Joinen werden gleiche Spaltennamen benötigt
stopwords_de &lt;- stopwords_de %&gt;% 
  rename(token = word)  

afd_long %&gt;% 
  anti_join(stopwords_de) -&gt; afd_no_stop</code></pre>
<p>Unser Datensatz hat jetzt viel weniger Zeilen; wir haben also durch <code>anti_join</code> Zeilen gelöscht (herausgefiltert). Das ist die Funktion von <code>anti_join</code>: Die Zeilen, die in beiden Dataframes vorkommen, werden herausgefiltert. Es verbleiben also nicht “Nicht-Stopwörter” in unserem Dataframe. Damit wird es schon interessanter, welche Wörter häufig sind.</p>
<pre class="r"><code>afd_no_stop %&gt;% 
  count(token, sort = TRUE) -&gt; afd_count</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-13">Table 1: </span>Die häufigsten Wörter</caption>
<thead>
<tr class="header">
<th align="left">token</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">deutschland</td>
<td align="right">190</td>
</tr>
<tr class="even">
<td align="left">afd</td>
<td align="right">171</td>
</tr>
<tr class="odd">
<td align="left">programm</td>
<td align="right">80</td>
</tr>
<tr class="even">
<td align="left">wollen</td>
<td align="right">67</td>
</tr>
<tr class="odd">
<td align="left">bürger</td>
<td align="right">57</td>
</tr>
<tr class="even">
<td align="left">euro</td>
<td align="right">55</td>
</tr>
<tr class="odd">
<td align="left">dafür</td>
<td align="right">53</td>
</tr>
<tr class="even">
<td align="left">eu</td>
<td align="right">53</td>
</tr>
<tr class="odd">
<td align="left">deutsche</td>
<td align="right">47</td>
</tr>
<tr class="even">
<td align="left">deutschen</td>
<td align="right">47</td>
</tr>
</tbody>
</table>
<p>Ganz interessant; aber es gibt mehrere Varianten des Themas “deutsch”. Es ist wohl sinnvoller, diese auf den gemeinsamen Wortstamm zurückzuführen und diesen nur einmal zu zählen. Dieses Verfahren nennt man “stemming” oder “trunkieren”.</p>
<pre class="r"><code>afd_no_stop %&gt;% 
  mutate(token_stem = wordStem(.$token, language = &quot;de&quot;)) %&gt;% 
  count(token_stem, sort = TRUE) -&gt; afd_count_stemmed

afd_count_stemmed %&gt;% 
  top_n(10) %&gt;% 
  knitr::kable(caption = &quot;Die häufigsten Wörter - mit &#39;stemming&#39;&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-14">Table 2: </span>Die häufigsten Wörter - mit ‘stemming’</caption>
<thead>
<tr class="header">
<th align="left">token_stem</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">deutschland</td>
<td align="right">219</td>
</tr>
<tr class="even">
<td align="left">afd</td>
<td align="right">171</td>
</tr>
<tr class="odd">
<td align="left">deutsch</td>
<td align="right">119</td>
</tr>
<tr class="even">
<td align="left">polit</td>
<td align="right">88</td>
</tr>
<tr class="odd">
<td align="left">staat</td>
<td align="right">85</td>
</tr>
<tr class="even">
<td align="left">programm</td>
<td align="right">81</td>
</tr>
<tr class="odd">
<td align="left">europa</td>
<td align="right">80</td>
</tr>
<tr class="even">
<td align="left">woll</td>
<td align="right">67</td>
</tr>
<tr class="odd">
<td align="left">burg</td>
<td align="right">66</td>
</tr>
<tr class="even">
<td align="left">soll</td>
<td align="right">63</td>
</tr>
</tbody>
</table>
<p>Das ist schon informativer. Dem Befehl <code>SnowballC::wordStem</code> füttert man einen Vektor an Wörtern ein und gibt die Sprache an (Default ist Englisch). Denken Sie daran, dass <code>.</code> bei <code>dplyr</code> nur den Datensatz meint, wie er im letzten Schritt definiert war. Mit <code>.$token</code> wählen wir also die Variable <code>token</code> aus <code>afd_raw</code> aus.</p>
</div>
<div id="visualisierung" class="section level3">
<h3>Visualisierung</h3>
<p>Zum Abschluss noch eine Visualisierung mit einer “Wordcloud” dazu (Abbildung <a href="#fig:show-wordcloud">2</a>).</p>
<pre class="r"><code>wordcloud(words = afd_count_stemmed$token_stem, 
          freq = afd_count_stemmed$n, 
          max.words = 100, 
          scale = c(2,.5), 
          colors=brewer.pal(6, &quot;Dark2&quot;))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:show-wordcloud"></span>
<img src="/images/textmining/wordcloud1.png" alt="Eine Wordwolke zum AfD-Parteiprogramm" width="100%" />
<p class="caption">
Figure 2: Eine Wordwolke zum AfD-Parteiprogramm
</p>
</div>
<p>Man kann die Anzahl der Wörter, Farben und einige weitere Formatierungen der Wortwolke beeinflussen<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>.</p>
<p>Weniger verspielt ist eine schlichte visualisierte Häufigkeitsauszählung dieser Art, z.B. mit Balkendiagrammen (gedreht), s. Abbildung <a href="#fig:p-word-freq">3</a>.</p>
<pre class="r"><code>afd_count_stemmed %&gt;% 
  top_n(30) %&gt;% 
  ggplot() +
  aes(x = reorder(token_stem, n), y = n) +
  geom_col() + 
  labs(title = &quot;mit Trunkierung&quot;) +
  coord_flip() -&gt; p1

afd_count %&gt;% 
  top_n(30) %&gt;% 
  ggplot() +
  aes(x = reorder(token, n), y = n) +
  geom_col() +
  labs(title = &quot;ohne Trunkierung&quot;) +
  coord_flip() -&gt; p2</code></pre>
<div class="figure" style="text-align: center"><span id="fig:p-word-freq"></span>
<img src="/post/2017-11-28-textmining-grundlagen_files/figure-html/p-word-freq-1.png" alt="Worthäufigkeiten im AfD-Parteiprogramm" width="100%" />
<p class="caption">
Figure 3: Worthäufigkeiten im AfD-Parteiprogramm
</p>
</div>
<p>Die beiden Diagramme vergleichen die trunkierten Wörter mit den nicht trunkierten Wörtern. Mit <code>reorder</code> ordnen wir die Spalte <code>token</code> nach der Spalte <code>n</code>. <code>coord_flip</code> dreht die Abbildung um 90°, d.h. die Achsen sind vertauscht.</p>
</div>
</div>
<div id="aufgaben" class="section level2">
<h2>Aufgaben<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></h2>

<div class="rmdexercises">
<p>Richtig oder Falsch!?</p>
<ol style="list-style-type: decimal">
<li>Unter einem Token versteht man die größte Analyseeinheit in einem Text.</li>
<li>In einem tidytext Dataframe steht jedes Wort in einer (eigenen) Zeile.</li>
<li>Eine hinreichende Bedingung für einen tidytext Dataframe ist es, dass in jeder Zeile ein Wort steht (beziehen Sie sich auf den tidytext Dataframe wie in diesem Kapitel erörtert).</li>
<li>Gibt es ‘Stop-Wörter’ in einem Dataframe, dessen Text analysiert wird, so kommt es - per definitionem - zu einem Stop.</li>
<li>Mit dem Befehl <code>unnest_tokens</code> kann man einen tidytext Dataframe erstellen.</li>
<li>Balkendiagramme sind sinnvolle und auch häufige Diagrammtypen, um die häufigsten Wörter (oder auch Tokens) in einem Corpus darzustellen.</li>
<li>In einem ‘tidy text Dataframe’ steht in jeder Zeile ein Wort (token) <em>aber nicht</em> die Häufigkeit des Worts im Dokument.</li>
<li>Unter ‘Stemming’ versteht man (bei der Textanalyse), die Etymologie eines Wort (Herkunft) zu erkunden.</li>
</ol>
</div>

</div>
<div id="verweise" class="section level2">
<h2>Verweise</h2>
<ul>
<li>Das Buch <em>Tidy Text Minig</em> ist eine hervorragende Quelle vertieftem Wissens zum Textmining mit R.</li>
</ul>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Nach dem Gedicht “Jahrgang 1899” von Erich Kästner<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Teil der Tidyverse-Familie<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Ggf. benötigen Sie Administrator-Rechte, um Dateien auf Ihre Festplatte zu speichern.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><geladen am 1. März 2017 von https://www.alternativefuer.de/wp-content/uploads/sites/7/2016/05/2016-06-27_afd-grundsatzprogramm_web-version.pdf><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>wie kann man sich die Anzahl der Wörter ausgeben lassen? Z.B. so: <code>count(afd)</code><a href="#fnref5">↩</a></p></li>
<li id="fn6"><p><a href="https://cran.r-project.org/web/packages/wordcloud/index.html" class="uri">https://cran.r-project.org/web/packages/wordcloud/index.html</a><a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>F, R, F, F, R, R, F, F<a href="#fnref7">↩</a></p></li>
</ol>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="/tags/rstats/">rstats</a>

  <a class="tag tag--primary tag--small" href="/tags/textmining/">textmining</a>

  <a class="tag tag--primary tag--small" href="/tags/polit/">polit</a>

  <a class="tag tag--primary tag--small" href="/tags/german/">German</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2017/11/grundlagen-des-textminings-mit-r-teil-2/" data-tooltip="Grundlagen des Textminings mit R - Teil 2">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2017/11/textmining-grundlagen/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2017/11/textmining-grundlagen/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2017/11/textmining-grundlagen/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2017 <a Sebastian Sauer CC-BY-SA 4.0 </a>. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2017/11/grundlagen-des-textminings-mit-r-teil-2/" data-tooltip="Grundlagen des Textminings mit R - Teil 2">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2017/11/textmining-grundlagen/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2017/11/textmining-grundlagen/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2017/11/textmining-grundlagen/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2017%2F11%2Ftextmining-grundlagen%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2017%2F11%2Ftextmining-grundlagen%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2017%2F11%2Ftextmining-grundlagen%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/8851f7754d1792f008b8874cd258f5b7?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Sebastian Sauer</h4>
    
      <div id="about-card-bio"><strong>Data Scie</strong>nce blog of Sebastian Sauer</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data enthusiast
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Nuremberg
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/textmining-grundlagen/">
                <h3 class="media-heading">Grundlagen des Textminings mit R</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Lernziele:
  - Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &#39;tidy text dataframe&#39; ist. - Sie können Worthäufigkeiten auszählen. - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren. In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen  Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/grundlagen-des-textminings-mit-r-teil-2/">
                <h3 class="media-heading">Grundlagen des Textminings mit R - Teil 2</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen library(skimr) # Überblicksstatistiken Aus dem letzten Post Daten einlesen:
osf_link &lt;- paste0(&quot;https://osf.io/b35r7//?action=download&quot;) afd &lt;- read_csv(osf_link) Aus breit mach lang:
afd %&gt;% unnest_tokens(output = token, input = content) %&gt;% dplyr::filter(str_detect(token, &quot;[a-z]&quot;)) -&gt; afd_long Stopwörter entfernen:
data(stopwords_de, package = &quot;lsa&quot;) stopwords_de &lt;- data_frame(word = stopwords_de) # Für das Joinen werden gleiche Spaltennamen benötigt stopwords_de &lt;- stopwords_de %&gt;% rename(token = word) afd_long %&gt;% anti_join(stopwords_de) -&gt; afd_no_stop Wörter zählen:</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/image-path-for-blogdown/">
                <h3 class="media-heading">Image path for blogdown</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">How to include external images to a hugo post?
Suppose we have a file img1.png in project1, ie., project1/img1.png. Do this:
Copy your folder with images to static/. Use this path in your blogdown post: /project/img1.png.   Mind the leading slash!  Example time This code (on my machine) ![](/images/textmining/tidytext-crop.png){ width=&quot;20%&quot; }
renders this:
 Note the nice width option.
 Knitr way The knitr way works similarly:
knitr::include_graphics(&quot;/images/textmining/tidytext-crop.png&quot;)  </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/test/">
                <h3 class="media-heading">test</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"> knitr way
knitr::include_graphics(&quot;/images/textmining/tidytext-crop.png&quot;) </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/dummy-variables-and-regression/">
                <h3 class="media-heading">Dummy variables and regression</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">For modeling cause-effect relationships, linear regression is among the most typically used methods.
Take, for example, the idea that the Gross Domestic Product (GDP) drives religiosity. Of course, we should have a strong theory that defends this choice and this directionality. Without a convincing theory it may be argued that the cause-relationship is the other way round or complete different (ie., some third variable accounts for any association between GDP and religiosity).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/interactive-diagrams-in-lieu-of-shiny/">
                <h3 class="media-heading">Interactive diagrams in lieu of shiny?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">One frequent use of the Shiny server software is displaying interactive data diagrams. The pro of using Shiny is the great flexibility; much more than “just graphics” can be done.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/my-favorite-stats-text-book/">
                <h3 class="media-heading">My favorite stats text book</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Some thoughts how my favorite applied stats text book would look like. I am looking at eg., business fields such as MBA as consumers.
My ideal applied stats text book is case study oriented (“Assume you would like to predict which movie will score highest next year based on some movie characteristics you know”)
 makes use of recent data analytics techniques such as tree based methods (Random Forests) or Shrinkage models (Lasso)</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/use-case-for-purrr-map/">
                <h3 class="media-heading">Use case for purrr::map</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">library(tidyverse) d &lt;- data_frame( id = c(1,1,1,1,1,1,2,2,3,3,3,4,1,2,2) ) d$id %&gt;% map </div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/compute-effect-sizes-with-r-a-primer/">
                <h3 class="media-heading">Compute effect sizes with R. A primer.</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">A typical “cook book recipe” for doing data analysis is an applied stats course is:
report descriptive statistics plot some nice diagrams test hypothesis report effect sizes  Let’s have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &quot;nycflights13&quot;) This post will be tidyverse-driven.
library(tidyverse) library(skimr) library(mosaic) Let’s compute some summaries:
flights %&gt;% select(arr_delay) %&gt;% skim #&gt; Skim summary statistics #&gt; n obs: 336776 #&gt; n variables: 1 #&gt; #&gt; Variable type: numeric #&gt; var missing complete n mean sd min p25 median p75 max #&gt; 1 arr_delay 9430 327346 336776 6.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/get-your-stats-result-in-a-table-easily/">
                <h3 class="media-heading">Get your stats result in a table easily</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Having computed some staticis, one would like to display them. Either in a figure, on in a table, that’s the two typical ways.
Let’s explore some helper functions to get your stats to a table easily.
A nice overview on packages can be found here.
Let’s have a quick glance at these steps. We will use the dataset flights of the package nycflights13.
data(flights, package = &quot;nycflights13&quot;) This post will be tidyverse-driven:</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         144 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/wildblue.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2017\/11\/textmining-grundlagen\/';
          
            this.page.identifier = '\/2017\/11\/textmining-grundlagen\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'https-sebastiansauer-github-io';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

