<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.6" />


<title>The effect of sample on p-values. A simulation. - Data Se</title>
<meta property="og:title" content="The effect of sample on p-values. A simulation. - Data Se">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo-data-se.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/">Blog</a></li>
    
    <li><a href="/privacy/">Data privacy</a></li>
    
    <li><a href="/students/">For Students</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">3 min read</span>
    

    <h1 class="article-title">The effect of sample on p-values. A simulation.</h1>

    
    <span class="article-date">2017/04/13</span>
    

    <div class="article-content">
      

<p>It is well-known that the notorious p-values is sensitive to sample size: The larger the sample, the more bound the p-value is to fall below the magic number of .05.</p>

<p>Of course, the p-value is also a function of the effect size, eg., the distance between two means and the respective variances. But still, the p-values tends to become significant in the face of larges samples, and non-significant otherwise.</p>

<p>Theoretically, quite simple and well understood. But let&rsquo;s take the test of &ldquo;real&rdquo; data and do a simulation to demonstrate or test this behavior.</p>

<p>First, load some required packages</p>

<pre><code class="language-r">library(tidyverse)
</code></pre>

<h1 id="simulate-data-with-large-sample-size">Simulate data with large sample size</h1>

<p>Next, we simulate data: A data frame of 20 cols and many rows (1e06, ie., 1 million). We should also make sure that the null hypothesis is <em>false</em> in our data. To that end, we let the mean values of the columns vary somewhat.</p>

<pre><code class="language-r">k &lt;- 20
n &lt;- 1e06
df &lt;- data.frame(replicate(k,rnorm(n = n, mean = rnorm(1, 0, 1), sd = 1)))
</code></pre>

<p>Now let&rsquo;s compute t-tests for each and every combination (cartesian product of all combinations). We will save the resulting p-values in a (square) matrix.</p>

<pre><code class="language-r">m &lt;- matrix(nrow = k, ncol = k)


for (i in seq_len(ncol(df))) {
  for (j in seq_len(ncol(df))) {
    m[i, j] &lt;- t.test(df[i], df[j])$p.value
  }
}
</code></pre>

<p>One half of the matrix is redundant, as the matrix is symmetric. The same reasoning applies for the diagonal. Let&rsquo;s take out the redundant elements.</p>

<pre><code class="language-r">m[lower.tri(m)] &lt;- NA
m[diag(m)] &lt;- NA
</code></pre>

<p>Let&rsquo;s come up with a logical matrix indicating whether one cell (ie., one t-test) indicates a significant t-test (<code>TRUE</code>) or not (<code>FALSE</code>).</p>

<pre><code class="language-r">m_significant &lt;- apply(m, c(1,2), function(x) x &lt; .05)
</code></pre>

<p>Finally, let&rsquo;s count the number of significant results, and sum then up.</p>

<pre><code class="language-r">m_significant %&gt;% sum(TRUE, na.rm = TRUE)
</code></pre>

<pre><code>## [1] 191
</code></pre>

<p>The number of different tests is $$(k*k - k)/2$$.</p>

<p>Which amounts, in this case to</p>

<pre><code class="language-r">(k*k-20)/2
</code></pre>

<pre><code>## [1] 190
</code></pre>

<p>Hence, all tests are significant.</p>

<pre><code class="language-r">rm(df)
</code></pre>

<h1 id="simulate-data-with-small-sample-size">Simulate data with small sample size</h1>

<p>Now, we repeat the same thing with a small sample.</p>

<pre><code class="language-r">simulate_ps &lt;- function(n = 1e06, k = 20){
  
  # arguments:
  # n: number of rows
  # k: number of columns
  # returns: proportion of significant (p&lt;.05) t-tests

set.seed(42)  
  
# simulate data
df &lt;- data.frame(replicate(k,rnorm(n = n, mean = rnorm(1, 0, 1), sd = 1)))

# matrix for t-test results
m &lt;- matrix(nrow = k, ncol = k)

# cartesian product of all t-tests
for (i in seq_len(ncol(df))) {
  for (j in seq_len(ncol(df))) {
    m[i, j] &lt;- t.test(df[i], df[j])$p.value
  }
}

# take-out redundant cells
m[lower.tri(m)] &lt;- NA
m[diag(m)] &lt;- NA

# compute matrix to count number of significant t-tests
m_significant &lt;- apply(m, c(1,2), function(x) x &lt; .05)


# count
sum_significant &lt;- m_significant %&gt;% sum(TRUE, na.rm = TRUE)

sum_distinct_tests &lt;- (k*k - k)/2

prop_significant &lt;- sum_significant / sum_distinct_tests

rm(df)
return(prop_significant)

}

simulate_ps(n = 10, k = 20)
</code></pre>

<pre><code>## [1] 0.5894737
</code></pre>

<h1 id="play-around">Play around</h1>

<p>Now, we can play around a bit.</p>

<pre><code class="language-r">ns &lt;- c(5, 10, 15, 20, 30, 40, 50, 100, 200, 300, 500, 1000, 2000, 5000, 10000, 2e04, 5e04, 1e05)

ps &lt;- vector(mode = &quot;numeric&quot;, length = length(ns))

for (i in seq_along(ns)){
  ps[i] &lt;- simulate_ps(n = ns[i], k = 20)
  print(ps[i])
}
</code></pre>

<pre><code>## [1] 0.4263158
## [1] 0.5894737
## [1] 0.5789474
## [1] 0.7315789
## [1] 0.6473684
## [1] 0.7736842
## [1] 0.8368421
## [1] 0.8631579
## [1] 0.9473684
## [1] 0.8842105
## [1] 0.9157895
## [1] 0.9736842
## [1] 0.9894737
## [1] 0.9894737
## [1] 0.9947368
## [1] 0.9947368
## [1] 1
## [1] 0.9947368
</code></pre>

<p>Finally, let&rsquo;s plot that:</p>

<pre><code class="language-r">data_frame(
  ns = ns,
  ps = ps
)  %&gt;% 
  ggplot +
  aes(x = ns, y = ps) +
  geom_line(color = &quot;gray80&quot;) +
  geom_point(color = &quot;firebrick&quot;)
</code></pre>

<p><img src="https://sebastiansauer.github.io/images/2017-04-13/figure/unnamed-chunk-11-1.png" title="plot of chunk unnamed-chunk-11" alt="plot of chunk unnamed-chunk-11" style="display: block; margin: auto;" /></p>

<p>Thus, our result appears reasonable: The larger the sample size (<code>ns</code>), the higher the proportion of ps (<code>ps</code>).</p>

    </div>
  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-data-se-netlify-com.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

