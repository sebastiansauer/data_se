<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on Data Se</title>
    <link>/tags/tutorial/</link>
    <description>Recent content in Tutorial on Data Se</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/tutorial/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Folien für Vortrag &#39;Papers publizieren&#39;</title>
      <link>/2019/01/04/folien-f%C3%BCr-vortrag-papiers-publizieren/</link>
      <pubDate>Fri, 04 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/04/folien-f%C3%BCr-vortrag-papiers-publizieren/</guid>
      <description>Die Folien für meinen Vortrag “Papers publizieren” zum Dozententreffen 2019 der FOM Hochschule liegen hier.</description>
    </item>
    
    <item>
      <title>Why standard regression is not (so) adequate for regressing proportions</title>
      <link>/2019/01/03/why-standard-regression-is-not-so-adequate-for-regressing-proportions/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/03/why-standard-regression-is-not-so-adequate-for-regressing-proportions/</guid>
      <description>Intro Professor Sweet is conducting some research to investigate the risk factor and drivers of student exam success. In a recent analysis he considers the variable “exam successfully passed” (vs. not passed) as the criterion (output) and the amount of time spent for preparation (aka study time) as predictor.
 Setup data(stats_test, package = &amp;quot;pradadata&amp;quot;) library(tidyverse) library(ggpubr) library(glue) library(ggExtra) library(broom) Let’s change some output formatting of ggplot (see this post for details)</description>
    </item>
    
    <item>
      <title>Easy way to convert factors zu numbers</title>
      <link>/2018/06/22/easy-way-to-convert-factors-zu-numbers/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/22/easy-way-to-convert-factors-zu-numbers/</guid>
      <description>Converting factors to numbers in R can be frustrating. Consider the following sitation: We have some data, and try to convert a factor (sex in tips, see below) to a numeric variable:
library(tidyverse) library(sjmisc) # for recoding data(tips, package = &amp;quot;reshape2&amp;quot;) glimpse(tips) #&amp;gt; Observations: 244 #&amp;gt; Variables: 7 #&amp;gt; $ total_bill &amp;lt;dbl&amp;gt; 16.99, 10.34, 21.01, 23.68, 24.59, 25.29, 8.77, 26.... #&amp;gt; $ tip &amp;lt;dbl&amp;gt; 1.01, 1.66, 3.50, 3.31, 3.61, 4.</description>
    </item>
    
    <item>
      <title>Convenient way to cite blog posts using Bibtex</title>
      <link>/2018/04/11/convenient-way-to-cite-blog-posts-using-bibtex/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/11/convenient-way-to-cite-blog-posts-using-bibtex/</guid>
      <description>Writing (scholarly) texts - a great way is using Markdown. Bibtext interacts nicely with Markdown, so one can easily cite literature.
One question that came up for me a couple of times recently was how to cite blogs in Bibtex?
I found this solution to be the most convenient:
@misc{stats_test, Author = {Sebastian Sauer}, Date-Added = {2018-03-29 13:54:38 +0000}, Date-Modified = {2018-03-29 13:55:51 +0000}, Doi = {10.17605/OSF.IO/SJHUY}, Howpublished = {Data Set}, Month = {01}, Title = {Results from an exam in inferential statistics}, Year = {2017}} The important points are the @misc class, and the Howpublished field.</description>
    </item>
    
    <item>
      <title>One-way ANOVA power analysis</title>
      <link>/2018/04/11/one-way-anova-power-analysis/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/11/one-way-anova-power-analysis/</guid>
      <description>Computing or estimating power is a very useful procedure in order to weigh the reliability of study results.
One frequent procedure in inferential statistics is the ANOVA, with the simplest form being the one-way ANOVA. This post shows how to compute power for this test.
What’s the effect size? The first thing to not is that there is no such thing as “power” - in the sense that a sample or a test would have “its power”.</description>
    </item>
    
    <item>
      <title>Why &#34;n-1&#34; in empirical variance? A simulation.</title>
      <link>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</guid>
      <description>It is well-known that the empirical variance underestimates the population variance. Specifically, the empirical variance is defined as: \(var_{emp} = \frac{\sum_i (x_i - \bar{x})^2}{n-1}\). But why \(n-1\), why not just \(n\), as intuition (of some) dictates? Put shortly, as the variance of a sample tends to underestimate the population variance we have to inflate it artificially, to enlarge it, that’s why we do put a smaller number (the “n-1”) in the denominator, resulting in a larger value of the whole fraction.</description>
    </item>
    
    <item>
      <title>Beispiel zu Simpsons Paradox</title>
      <link>/2018/03/16/beispiel-zu-simpsons-paradox/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/16/beispiel-zu-simpsons-paradox/</guid>
      <description>In diesem Post diskutieren wir ein Beispiel zu Simpson’s Paradox. Der Fokus liegt nicht auf der R-Syntax, sondern auf einer intuitiven Erläuterung des Simpson Paradox. (Die Syntax findet sich in ähnlicher Form in diesem Post.)
Sagen wir, Sie müssen sich zwischen zwei Ärzten (Dr. Arriba und Dr. Bajo) entscheiden und fragen sich, welcher “besser” ist. Unter “besser” verstehen Sie “höhere Heilungsquote”.
Die beiden Ärzte behandeln die gleichen zwei Krankheiten: Severitis und Nervosia maskulina.</description>
    </item>
    
    <item>
      <title>Tangible data of normal distributed data</title>
      <link>/2018/03/16/tangible-data-of-normal-distributed-data/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/16/tangible-data-of-normal-distributed-data/</guid>
      <description>A classical example for a normally distributed variable is height. However, I kept on looking for data as to the mean and sd for some populations, such as Germany. Now I found some reliably looking data here.
We will not question whether the assumption of normality holds, we just assume it.
In the source, we can read that in Germany, the adult men population has the following parameters:
mean: 174cm</description>
    </item>
    
    <item>
      <title>Map students to presentation slots</title>
      <link>/2018/03/11/map-students-to-presentation-slots/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/11/map-students-to-presentation-slots/</guid>
      <description>As a teacher, I not only teach but also assess the achievements of students. One example of a typical student assignments is a presentation. You know, powerpoint slides and stuff.
For that purpose, I often need to map students to one of several time slots. Here’s the R code I use for that purpose.
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.</description>
    </item>
    
    <item>
      <title>Intuition to Simpson&#39;s paradox</title>
      <link>/2018/03/09/intuition-to-simpson-s-paradox/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/09/intuition-to-simpson-s-paradox/</guid>
      <description>Say, you have to choose between two doctors (Anna and Berta). To decide which one is better, you check their success rates. Suppose that they deal with two conditions (Coolities and Dummities). So let’s compare their success rate for each of the two conditions (and the total success rate):
This is the proportion of healing (success) of the first doctor, Dr. Anna for each of the two conditions:
 Coolities: 7 out of 8 patients are healed from Coolities Dummieties: 1 out of 2 patients are healed from Dummities  This is the proportion of healing (success) of the first doctor, Dr.</description>
    </item>
    
    <item>
      <title>How to create columns in a dataframe in R</title>
      <link>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</guid>
      <description>Note that we will use this library for this post:
library(dplyr) ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.1 ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union By the way, loading mosaic, will load dplyr too.
One of the major data wrangling activities (in R and elsewhere) is to create a new column in a data frame.</description>
    </item>
    
    <item>
      <title> Wie gut schätzt eine Stichprobe die Grundgesamtheit?</title>
      <link>/2017/11/17/inference/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/17/inference/</guid>
      <description>Daten Sie arbeiten bei der Flughafenaufsicht von NYC. Cooler Job.
library(nycflights13) data(flights)  Pakete laden library(mosaic)  Stichprobe ziehen Die Aufsichtsbehörde zieht eine Probe von 100 Flügen und ermittelt die &amp;ldquo;typische&amp;rdquo; Verspätung.
set.seed(42) sample(flights$arr_delay, size = 100) -&amp;gt; flights_sample  Und berechnen wir die typischen Kennwerte:
favstats(~flights_sample, na.rm = TRUE) #&amp;gt; min Q1 median Q3 max mean sd n missing #&amp;gt; -51 -18.75 -5 11.75 150 0.4387755 31.1604 98 2  Ob $n=3$ ausreichen würde?</description>
    </item>
    
    <item>
      <title>A predictor&#39;s unique contribution - (visual) demonstration</title>
      <link>/2017/05/17/storks/</link>
      <pubDate>Wed, 17 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/17/storks/</guid>
      <description>A well-known property of regression models is that they capture the unique contribution of a predictor. By &amp;ldquo;unique&amp;rdquo; we mean the effect of the predictor (on the criterion) if the other predictor(s) is/are held constant. A typical classroom example goes along the following lines.
All about storks  There&amp;rsquo;s a correlation between babies and storks. Counties with lots of storks enjoy large number of babies and v.v.
 However, I have children, I know the storks are not overly involved in that business, so says the teacher (polite laughters in the audience).</description>
    </item>
    
    <item>
      <title>Crashkurs Datenanalyse mit R</title>
      <link>/2017/05/16/crashkurs/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/16/crashkurs/</guid>
      <description>Nicht jeder liebt Datenanalyse und Statistik&amp;hellip; in gleichem Maße. Das ist zumindest meine Erfahrung aus dem Unterricht 🔥. Crashkurse zu R sind vergleichbar zu Crahskursen zu Französisch - kann man machen, aber es sollte die Maxime gelten &amp;ldquo;If everything else fails&amp;rdquo;.
Dieser Crashkurs ist für Studierende oder Anfänger der Datenanalyse gedacht, die in kurzer Zeit einen verzweifelten Versuch &amp;hellip; äh &amp;hellip; einen grundständigen Überblick über die Datenanalyse erwerben wollen.</description>
    </item>
    
    <item>
      <title>Crashkurs Datenanalyse mit R</title>
      <link>/2017/05/16/crashkurs/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/16/crashkurs/</guid>
      <description>Nicht jeder liebt Datenanalyse und Statistik… in gleichem Maße. Das ist zumindest meine Erfahrung aus dem Unterricht :neckbeard: :fire:. Crashkurse zu R sind vergleichbar zu Crahskursen zu Französisch - kann man machen, aber es sollte die Maxime gelten “If everything else fails”.
Dieser Crashkurs ist für Studierende oder Anfänger der Datenanalyse gedacht, die in kurzer Zeit einen verzweifelten Versuch … äh … einen grundständigen Überblick über die Datenanalyse erwerben wollen.</description>
    </item>
    
    <item>
      <title>Deriving the logits for logistic regression</title>
      <link>/2017/05/06/deriving-the-logits-for-logistic-regression/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/06/deriving-the-logits-for-logistic-regression/</guid>
      <description>The logistic regression is an incredible useful tool, partly because binary outcomes are so frequent in live (“she loves me - she doesn’t love me”). In parts because we can make use of well-known “normal” regression instruments.
But the formula of logistic regression appears opaque to many (beginners or those with not so much math background).
Let’s try to shed some light on the formula by discussing some accessible explanation on how to derive the formula.</description>
    </item>
    
    <item>
      <title>Checklist for Data Cleansing</title>
      <link>/2017/02/13/data_cleansing/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/02/13/data_cleansing/</guid>
      <description>What this post is about: Data cleansing in practice with R Data analysis, in practice, consists typically of some different steps which can be subsumed as &amp;ldquo;preparing data&amp;rdquo; and &amp;ldquo;model data&amp;rdquo; (not considering communication here):
(Inspired by this)
Often, the first major part &amp;ndash; &amp;ldquo;prepare&amp;rdquo; &amp;ndash; is the most time consuming. This can be lamented since many analysts prefer the cool modeling aspects (since I want to show my math!</description>
    </item>
    
    <item>
      <title>Convert logit to probability</title>
      <link>/2017/01/24/convert_logit2prob/</link>
      <pubDate>Tue, 24 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/01/24/convert_logit2prob/</guid>
      <description>Logistic regression may give a headache initially. While the structure and idea is the same as &amp;ldquo;normal&amp;rdquo; regression, the interpretation of the b&amp;rsquo;s (ie., the regression coefficients) can be more challenging.
This post provides a convenience function for converting the output of the glm function to a probability. Or more generally, to convert logits (that&amp;rsquo;s what spit out by glm) to a probabilty.
Note1: The objective of this post is to explain the mechanics of logits.</description>
    </item>
    
    <item>
      <title>Gentle intro to &#39;R-squared equals squared r&#39;</title>
      <link>/2017/01/20/rsquared/</link>
      <pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/01/20/rsquared/</guid>
      <description>It comes as no surprise that $$R^2$$ (&amp;ldquo;coefficient of determination&amp;rdquo;) equals $$r^2$$ in simple regression (predictor X, criterion Y), where $$r(X,Y)$$ is Pearson&amp;rsquo;s correlation coefficient. $$R^2$$ equals the fraction of explained variance in a simple regression. However, the statistical (mathematical) background is often less clear or buried in less-intuitive formula.
The goal of this post is to offer a gentle explanantion why
$$R^2 = r^2$$,
where $$r$$ is $$r(Y,\hat{Y})$$ and $$\hat{Y}$$ are the predicted values.</description>
    </item>
    
    <item>
      <title>How to import a strange CSV</title>
      <link>/2017/01/12/strange_csvs/</link>
      <pubDate>Thu, 12 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/01/12/strange_csvs/</guid>
      <description>A typical task in data analysis is to import CSV-formatted data. CSV is nothing more than a text file with data in rectangular form; rows stand for observations (eg., persons), and columns represent variables (such as age). Columns are separed by a &amp;ldquo;separator&amp;rdquo;, often a comma. Hence the name &amp;ldquo;CSV&amp;rdquo; - &amp;ldquo;comma separeted values&amp;rdquo;. Note however that the separator can in principle anything you like (eg., &amp;ldquo;;&amp;rdquo; or tabulator or &amp;ldquo; &amp;ldquo;).</description>
    </item>
    
    <item>
      <title>Why is the variance additive? An intuition.</title>
      <link>/2017/01/04/additivity_variance/</link>
      <pubDate>Wed, 04 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/01/04/additivity_variance/</guid>
      <description>The variance of some data can be defined in rough terms as the mean of the squared deviations from the mean.
Let&amp;rsquo;s repeat that because it is important:
 Variance: Mean of squared deviations from the mean.
 An example helps to illustrate. Assume some class of students are forced to write an exam in a statistics class (OMG). Let&amp;rsquo;s say the grades range fom 1 to 6, 1 being the best and 6 the worst.</description>
    </item>
    
    <item>
      <title>Simulation of p-values</title>
      <link>/2016/12/01/simu_p/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/12/01/simu_p/</guid>
      <description>Teaching or learning stats can be a challenging endeavor. In my experience, starting with concrete (as opposed to abstract) examples helps many a learner. What also helps (for me) is visualizing.
As p-values are still part and parcel of probably any given stats curriculum, here is a convenient function to simulate p-values and to plot them.
&amp;ldquo;Simulating p-values&amp;rdquo; amounts to drawing many samples from a given, specified population (eg., µ=100, s=15, normally distributed).</description>
    </item>
    
  </channel>
</rss>