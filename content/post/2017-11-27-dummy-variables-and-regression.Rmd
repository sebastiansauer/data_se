---
title: Dummy variables and regression
author: Sebastian Sauer
date: '2017-11-27'
slug: dummy-variables-and-regression
categories:
  - rstats
tags:
  - rstats
---


```{r echo = FALSE}
knitr::opts_chunk$set(
  cache = FALSE
)
```


For modeling cause-effect relationships, linear regression is among the most 
typically used methods.

Take, for example, the idea that the Gross Domestic Product (GDP) drives religiosity.
Of course, we should have a strong theory that defends this choice and this 
directionality. Without a convincing theory it may be argued that the cause-relationship
is the other way round or complete different (ie., some third variable accounts for any
association between GDP and religiosity).

Let's have a look at some data to illustrate.

First, we load some packages.
```{r}
library(tidyverse)  # do all
library(broom)  # tidy
library(DiagrammeR)  # graphs
```

This dataset deals with the aforementioned association:

```{r}
data <- read_csv("https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/Stat2Data/ReligionGDP.csv")
glimpse(data)
```


The path (cause-effect) diagram would look like this:

```{r}
DiagrammeR::grViz("
                  digraph rmarkdown{
                  rankdir=LR;
                  GDP -> Religiosity;
                  }",
                  height = 200)
```

Let's say our model insists this:

```{r}
DiagrammeR::grViz("
                  digraph rmarkdown{
                  rankdir=LR;
                  GDP -> Religiosity;
                  Region -> Religiosity
                  }",
                  height = 200)
```


Of course, a more realistic path diagram might look like this:

```{r}
DiagrammeR::grViz("
                  digraph rmarkdown{
                  graph [fontsize = 10; rankdir=LR]

                  node [fontname = Helvetica]
                  GDP; Religiosity; X; Y1; Y2; M1; M2; Region
                  
                  GDP -> Religiosity
                  GDP -> M1
                  M -> Religiosity
                  X -> Religiosity
                  Y1 -> GDP
Region -> GDP
Region -> Religiosity
Region -> M2
Y2 -> Region
M2 -> Religiosity
                  }")
```

So, in short, this model holds that both Region and GDP have an indirect and and direct effect on Religiosity, but there are other influences on Religiosity, too. And GDP and Region are in turn influenced by some other factors.

Anyway, let's try to model the simple model using a linear model.


# I have no column `Region`

My path diagram says I need a column `Region` but there's none in my data set! Instead, there are a bunch of columns like "Africa", "MiddleEast" where each country is coded with $1$ or $0$ if it is part of the region or not, respectively. Variables like those are called *dummy variables* (or indicator variables, or binary variables).

# Now what?

Basically, a linear model only understands numerical data as predictor(s). Simply put, on the X-axis there must always be numeric data. A dummy variable can be seen as numeric - possessing only two distinct values, $0$ and $1$!. That's why dummy variables work for regression. By the way, many models think this way.  So we are in the position to run our regression right away:


```{r}
lm1 <- lm(Religiosity ~ GDP + Africa + MiddleEast + Asia + WestEurope + Americas, data = data)
tidy(lm1)
```

That's the way a linear model operates. 

The output tells us the *difference* in Religiosity between the states `0` and `1` of that variable. Hm, that works numerically, but does not make much sense. What does it mean if *all* regions are at values $0$? Not much.

We are better to take out one region, define it as baseline or comparison region, and compare each region against that region. If all the remaining region variables are at $0$ that means that we are looking at this baseline region.




# Build a long data frame

The good news is that `lm()` takes care of that. We don't have to do much. We just give one column `Region` and `lm()` will sort out the rest.

So let's build this column:

```{r}
data_long <- gather(data, key = Region, value = is_part, -c(X1, Country, Religiosity, GDP))
data_long <- filter(data_long, is_part == 1)
glimpse(data_long)
```


# Run the regression with `Region`

```{r}
lm2 <- lm(Religiosity ~ GDP + Region, data = data_long)
tidy(lm2)
```


As we can see, the effect of `GDP` remains the same. What has changed is that `Africa`, being the first value in alphabetical order, is not defined as the baseline region. Hence, `Africa` does not appear as predictor, because the remaining regions are compared with Africa.

What about model performance:

```{r}
glance(lm2)
```


Is model 2 better ($R^2$) than model 1?

```{r}
round(glance(lm2)$adj.r.squared, 2) == round(glance(lm1)$adj.r.squared, 2)
```

Both models are equal in their performance, which makes sense since the data is the same.


# Viz


For visualization and many typical reports, it is necessary to have on column `Region`.


```{r}
qplot(y = GDP,
      x = Region,
      data = data_long,
      geom  = "boxplot")
```





Let's sort the boxplots and flip the axes:

```{r}
qplot(y = Religiosity, 
      x = reorder(Region, Religiosity), 
      data = data_long,
      geom = "boxplot") +
  coord_flip() +
  labs(x = "Region")
```

