---
title: Why "n-1" in empirical variance? A simulation.
author: Sebastian Sauer
date: '2018-03-24'
slug: why-n-1-in-empirical-variance-a-simulation
categories:
  - rstats
tags:
  - tutorial
  - intuition
  - r
---


It is well-known that the empirical variance underestimates the population variance. Specifically, the empirical variance is defined as: $var_{emp} = \frac{\sum_i x_i - \bar{x}}{n-1}$. But why $n-1$, why not just $n$, as intuition (of some) dictates? Put shortly, as the empirical variance tends to underestimates the population variance we have to inflate it artificially, to enlarge it, that's why we do put a *smaller* number in the denominator, resulting in a *larger* value of the whole fraction.

In this post, we will not prove this relationship, but we will test it empirically. That is, we will let R draw samples and check whether the variance of the samples is slightly smaller than the variance in the population.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE, 
                      fig.align = "center")
```

Load some packages:

```{r}
library(tidyverse)
library(magrittr)
```


Then we'll define a function that computes the empirical variance `var_emp` from a sample taken of a standard normal distribution.


```{r}
var_emp <- function(n = 10) {
  
  rnorm(n = n, mean = 0, sd = 1) %>% 
    var()
}

# test it:
set.seed(42)
var_emp()
```


By the way, to get the variance (or sd) of a *sample* as a description of the sample, we can use this computation:


```{r}
n <- 10  # sample size
n_max <- 200  # max sample size to consider later on


var_sample <- function(n = 10) {
  
  rnorm(n = n, mean = 0, sd = 1) %>% 
      var(.) %>% 
     `*`((n-1)/n)
}

set.seed(42)
var_sample()
```

The "correction" amounts to a factor of .9 in the case of $n=10$, ie., $(10-1)/10$.

But one sample is not sufficient to gauge an overall picture. Rather let's draw many samples, say $m=1000$, and compute the empirical variance and the sample variance each time.


```{r}
m <- 1000
df_variance <- data_frame(id = 1:m)

df_variance %<>% 
  mutate(var_emp_vec = replicate(n = m, var_emp()),
         var_sample_vec = replicate(n = m, var_sample())) %>% 
  gather(key = variance_type, value = variance, -id)
```

See here the distributions:

```{r} 
df_variance %>% 
  ggplot() +
  aes(x = variance, fill = variance_type) +
  geom_density(alpha = .5)
```


What's the central tendency in each case?
```{r}
df_variance %>% 
  group_by(variance_type) %>% 
  summarise(mean_variance = mean(variance))
```

What about the quantiles of this sampling distribution?
```{r}
df_variance %>% 
  split(.$variance_type) %>% 
  map(~quantile(.$variance, probs = c(.055, .5, .945)))

```


Our results show that the variance of the sample is smaller than the empirical variance; however even the empirical variance is a little too small compared with the population variance (which is 1). Note that sample size was $n=10$ in each draw of the simulation. With sample size increasing, both should get closer to the "real" (population) sample size (although the bias is negligible for the empirical variance). Let's check that.



First let's define a function which does the simulation for a given sample size $n$ and a given number of samples, $m$.



```{r}
simu_mean <- function(n = 10, m = 1000, correction = 1){
  replicate(n = m, var_emp(n = n) * correction) %>% 
  mean()
}
```

This function draws a sample of size $n$, computes the (empirical) variance, and multiply the result with a correction factor if needed (to estimate the sample variance). This procedure is repeated for $m$ times. Finally, all $m$ variance values are averaged:

```{r}
simu_mean()

```


Now we let this function run for different samples sizes:


```{r}
sizes <- 2:n_max



sizes %>% 
  map_dbl(~simu_mean(n = .)) %>% 
  as_tibble -> simu_df

simu_df %<>%
  mutate(sample_size = sizes)

names(simu_df)[1] <-"variance_empirical"
```


Finally, let's plot the resulting curve:

```{r}
simu_df %>% 
  ggplot +
  aes(x = sample_size, y = variance_empirical) +
  geom_line() +
  scale_y_continuous(limits = c(0.5, 1.5))
```


Even with small samples, the variance is close to the real variance in the population (1).

Compare this to the sample size curve when the variance is computing with $n$ in the denominator (instead of $n-1$).


```{r}
sizes <-2:n_max

sizes %>% 
  map_dbl(~simu_mean(n = ., correction = (. -1) / .)) %>% 
  as_tibble -> simu_df_sample

simu_df_sample %<>% 
  mutate(sample_size = sizes) 

names(simu_df_sample)[1] <-"variance_sample"

```


```{r}
simu_df %>% 
  left_join(simu_df_sample, by = "sample_size") %>% 
  gather(key = variance_type, value = variance_value, -sample_size) %>% 
  ggplot() +
  aes(x = sample_size, y = variance_value, color = variance_type) +
  geom_line()
```


The sample variance underestimates the true value of the variance - at least for small samples. This bias diminishes when sample size increases.


