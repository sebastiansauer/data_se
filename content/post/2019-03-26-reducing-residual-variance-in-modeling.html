---
title: Reducing residual variance in modeling
author: Sebastian Sauer
date: '2019-03-26'
slug: reducing-residual-variance-in-modeling
categories:
  - rstats
tags:
  - tutorial
---



<p>Modeling is a central part not only of statistical inquiry, but also of everyday human sense-making. We use models as metaphors for the world, in a broader sense. Of course, a model that explains the world better (than some other model) is to be preferred, all other things being equal. In this post, we demonstrate that a more “clever” statistical model reduces the residual variance. It should be noted that this “noise reduction” comes at a cost, however: The model gets more complex; there a more parameters in the model.</p>
<p>First, let’s load some data and usual packages:</p>
<pre class="r"><code>library(tidyverse)
library(mosaic)
library(gridExtra)

data(tips, package = &quot;reshape2&quot;)</code></pre>
<p>We filter only the extreme groups in order to carve out the effect more lucidly. In addition, let’s compute the residuals and the square residuals:</p>
<pre class="r"><code>tips2 &lt;- filter(tips, size %in% c(1, 6)) %&gt;% 
  mutate(ID = 1:nrow(.),
         tip_resid = tip - mean(tip),
         tips_resid_quad =tip_resid^2) %&gt;% 
  group_by(size) %&gt;% 
  mutate(tip_mean_group = mean(tip))

glimpse(tips2)</code></pre>
<pre><code>## Observations: 8
## Variables: 11
## Groups: size [2]
## $ total_bill      &lt;dbl&gt; 3.07, 10.07, 7.25, 29.80, 34.30, 27.05, 48.17, 8…
## $ tip             &lt;dbl&gt; 1.00, 1.83, 1.00, 4.20, 6.70, 5.00, 5.00, 1.92
## $ sex             &lt;fct&gt; Female, Female, Female, Female, Male, Female, Ma…
## $ smoker          &lt;fct&gt; Yes, No, No, No, No, No, No, Yes
## $ day             &lt;fct&gt; Sat, Thur, Sat, Thur, Thur, Thur, Sun, Fri
## $ time            &lt;fct&gt; Dinner, Lunch, Dinner, Lunch, Lunch, Lunch, Dinn…
## $ size            &lt;int&gt; 1, 1, 1, 6, 6, 6, 6, 1
## $ ID              &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8
## $ tip_resid       &lt;dbl&gt; -2.33125, -1.50125, -2.33125, 0.86875, 3.36875, …
## $ tips_resid_quad &lt;dbl&gt; 5.4347266, 2.2537516, 5.4347266, 0.7547266, 11.3…
## $ tip_mean_group  &lt;dbl&gt; 1.4375, 1.4375, 1.4375, 5.2250, 5.2250, 5.2250, …</code></pre>
<p><code>tip_mean_group</code> refers to the mean value of the response variable <code>tip</code> for each conditioned group.</p>
<p>Next, we compute a helper data frame that stores the group means only:</p>
<pre class="r"><code>tips_sum &lt;- tips2 %&gt;% 
  group_by(size) %&gt;% 
  summarise(tip = mean(tip))</code></pre>
<p>Now, let’s plot:</p>
<p>That’s the plot for the <em>simpler</em> model without consideration of subgroups. We model the target variable <code>tip</code> as the grand mean (of the whole data set).</p>
<pre class="r"><code>p2 &lt;- ggplot(tips2) +
  geom_hline(aes(yintercept = mean(tip))) +
  geom_segment(aes(x = ID,
                   xend = ID,
                   y = tip,
                   yend = mean(tip)),
               color = &quot;grey80&quot;) +
  geom_point(aes(x = ID, y = tip)) +
  labs(title = &quot;tip ~ 1&quot;)
p2</code></pre>
<p><img src="/post/2019-03-26-reducing-residual-variance-in-modeling_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>In contrast, consider the residuals when conditioned on the subgroup means:</p>
<pre class="r"><code>p1 &lt;- ggplot(tips2) +
  geom_hline(data = tips_sum,
            aes(yintercept = tip,
                color = factor(size))) +
  geom_segment(aes(x = ID,
                   xend = ID,
                   y = tip,
                   yend = tip_mean_group),
               color = &quot;grey80&quot;) +
  geom_point(aes(x = ID, y = tip,
                 color = factor(size))) +
  theme(legend.position = &quot;none&quot;) +
  labs(title = &quot;tip ~ size&quot;)
p1</code></pre>
<p><img src="/post/2019-03-26-reducing-residual-variance-in-modeling_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>As can be seen, the residuals become <em>smaller</em> in this model: The more complex model, where the target variable is modeled as the subgroup average, explains the data better. This models shows a better fit to the data.</p>
<pre class="r"><code>grid.arrange(p2, p1, nrow = 1)</code></pre>
<p><img src="/post/2019-03-26-reducing-residual-variance-in-modeling_files/figure-html/unnamed-chunk-6-1.png" width="100%" /></p>
